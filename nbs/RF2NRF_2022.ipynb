{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b896c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecea81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from typing import List, Callable\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19858082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_print(ctx, n=20):\n",
    "    res1 = decrypt(secretKey, ctx)\n",
    "    print(res1[:n])\n",
    "    \n",
    "def decrypt(secretKey, enc):\n",
    "    featurized = scheme.decrypt(secretKey, enc)\n",
    "    arr = np.zeros(n, dtype=np.complex128)\n",
    "    featurized.__getarr__(arr)\n",
    "    return arr.real\n",
    "\n",
    "def encrypt(val):\n",
    "    ctxt = he.Ciphertext()#logp, logq, n)\n",
    "    vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "    vv[:len(val)] = val\n",
    "    scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "    del vv\n",
    "    return ctxt\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class TabularDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        'Initialization'\n",
    "        self.X, self.y = X,y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.tensor(self.X[index]).float()\n",
    "        y = torch.tensor(self.y[index])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "class Param():\n",
    "    def __init__(self, n=None, logn=None, logp=None, logq=None, logQboot=None):\n",
    "        self.n = n\n",
    "        self.logn = logn\n",
    "        self.logp = logp\n",
    "        self.logq = logq \n",
    "        self.logQboot = logQboot\n",
    "        if self.logn == None:\n",
    "            self.logn = int(np.log2(n))\n",
    "            \n",
    "CAM_LIST= {1: \"e\",\n",
    "           2: \"e\",\n",
    "           3: \"a\",\n",
    "           4: \"e\",\n",
    "           5: \"e\",\n",
    "           6: \"e\",\n",
    "           7: \"e\",\n",
    "           8: \"a\",\n",
    "           9: \"a\",\n",
    "           10:\"e\",\n",
    "           11:\"e\",\n",
    "           12:\"e\",\n",
    "           13:\"a\",\n",
    "           14:\"e\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29953609",
   "metadata": {},
   "source": [
    "# Train a RF model  -- smaller example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401e18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.metrics import accuracy\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c98f5",
   "metadata": {},
   "source": [
    "matcher를 풀고 train하면 성능이 쉽게 올라가지만 중간에 계산값이 +/- 1을 넘어갈 가능성이 높아질 것 같음.  \n",
    "근데 matcher 안 풀고는 좀처럼 성능이 올라가지 않음... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece03e9",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fb1640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "min max of input dataset\n",
      "0.0 1.0000000000000002\n",
      "0.0 1.0000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/bbs/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/hoseung/anaconda3/envs/bbs/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./\"\n",
    "\n",
    "action = 14\n",
    "cam = CAM_LIST[action]\n",
    "\n",
    "fn_model_out = f\"trained_model_{action}_{cam}.pickle\"\n",
    "fn_data_out = f\"BBS_dataset_{action}_{cam}.pickle\"\n",
    "\n",
    "fn_model = model_dir + fn_model_out\n",
    "fn_dat = model_dir + fn_data_out\n",
    "\n",
    "rf_model = pickle.load(open(fn_model, \"rb\"))\n",
    "\n",
    "print(\"model's depth:\", rf_model.max_depth)\n",
    "print(\"model's tree count:\", rf_model.n_estimators)\n",
    "\n",
    "\n",
    "#####\n",
    "dataset = pickle.load(open(fn_dat, \"rb\"))\n",
    "\n",
    "X_train = dataset[\"train_x\"]\n",
    "y_train = dataset[\"train_y\"]\n",
    "X_valid = dataset[\"valid_x\"]\n",
    "y_valid = dataset[\"valid_y\"]\n",
    "\n",
    "print(\"min max of input dataset\")\n",
    "print(X_train.min(), X_train.max())\n",
    "print(X_valid.min(), X_valid.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24c27ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnrf\n",
    "\n",
    "from hnrf.nrf import NeuralTreeMaker, NeuralRF\n",
    "from sklearn.tree import BaseDecisionTree\n",
    "\n",
    "dilatation_factor = 15\n",
    "polynomial_degree = 31\n",
    "\n",
    "estimators = rf_model.estimators_\n",
    "\n",
    "my_tm_tanh = NeuralTreeMaker(torch.tanh, \n",
    "                            use_polynomial=True,\n",
    "                            dilatation_factor=dilatation_factor, \n",
    "                            polynomial_degree=polynomial_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806b824",
   "metadata": {},
   "source": [
    "A Neural Decision Tree consists of: \n",
    "1. activation function\n",
    "2. Coeffs\n",
    "3. weight loader \n",
    "4. forward method \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e13f383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.9737470167064439\n",
      "Accuracy of tanh : 0.5091487669053302\n",
      "Match between tanh and original : 0.522673031026253\n"
     ]
    }
   ],
   "source": [
    "Nmodel =NeuralRF(estimators, my_tm_tanh)\n",
    "\n",
    "# NRF 성능 테스트\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_train).float()).argmax(dim=1).numpy()\n",
    "\n",
    "pred = rf_model.predict(X_train)\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "print(f\"Accuracy of tanh : {(neural_pred == y_train).mean()}\")\n",
    "print(f\"Match between tanh and original : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2d47e",
   "metadata": {},
   "source": [
    "## Refine NRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc1ecb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([241, 87, 20]) False\n",
      "torch.Size([87, 20]) False\n",
      "torch.Size([88, 87, 20]) False\n",
      "torch.Size([88, 20]) False\n",
      "torch.Size([5, 88, 20]) True\n",
      "torch.Size([5, 20]) True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.670049</td>\n",
       "      <td>2.002182</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.806101</td>\n",
       "      <td>1.385068</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.484081</td>\n",
       "      <td>1.092441</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.301478</td>\n",
       "      <td>1.024366</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.187564</td>\n",
       "      <td>1.010556</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.9345380156836004\n",
      "Accuracy : 0.7178656665530174\n",
      "Same output : 0.753835663143539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "from hnrf.misc import CrossEntropyLabelSmoothing\n",
    "\n",
    "# Fine tuning\n",
    "Nmodel.freeze_layer(\"comparator\")\n",
    "Nmodel.freeze_layer(\"matcher\")\n",
    "\n",
    "for p in Nmodel.parameters():\n",
    "    print(p.shape, p.requires_grad)\n",
    "\n",
    "bs = 128\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "valid_ds = TabularDataset(X_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "learn = Learner(dls, Nmodel, loss_func=CrossEntropyLabelSmoothing())\n",
    "\n",
    "learn.lr_find()\n",
    "#learn.recorder.plot()\n",
    "learn.fit_one_cycle(5, 0.3)\n",
    "\n",
    "## Fine-tuned NRF model\n",
    "pred = rf_model.predict(X_valid)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_valid).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_valid).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_valid).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")\n",
    "\n",
    "save = False\n",
    "if save:\n",
    "    pickle.dump(Nmodel, open(f\"Nmodel_{action}_{cam}.pickle\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b07ef",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff42b4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5866, 241])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(X_valid).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2194cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnrf.hnrf import HEDT\n",
    "homomorphic_trees = [HEDT(w0, b0, w1, b1, w2, b2)\n",
    "                    for (w0, b0, w1, b1, w2, b2) in zip(*Nmodel.return_weights())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9cd59",
   "metadata": {},
   "source": [
    "Input vector = 241 = 30*8 + 1 (N_tot_frame 비슷한 거였음)\n",
    "\n",
    "weight = 87 < 128. 질문들. \n",
    "\n",
    "따라서, \n",
    "\n",
    "241 * 87(<128) * 20 만큼의 곱하기 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b1a1125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([241, 87, 20])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.comparator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13d931ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([87, 20])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.comparator_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2303cc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 87, 20])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.matcher.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bd1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2551b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum(\"kj,jil->kil\", x, Nmodel.comparator) + Nmodel.comparator_bias.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "797ae0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = homomorphic_trees[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53056e4f",
   "metadata": {},
   "source": [
    "HEDT가 multiplication 준비하는 단계. \n",
    "여기에 새 mat_mult위한 준비 필요. \n",
    "\n",
    "matrix 곱하기 모양은 nrf.py에서 확인. \n",
    "compare, match, decide 모두 torch.einsum으로 돌아감. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bf2d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hemul.matrix import MatrixMultiplicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076d539",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e0892c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mm \u001b[38;5;241m=\u001b[39m MatrixMultiplicator(\u001b[43md\u001b[49m, create_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: np\u001b[38;5;241m.\u001b[39mzeros(d\u001b[38;5;241m*\u001b[39md), \n\u001b[1;32m      2\u001b[0m                         \u001b[38;5;66;03m#sigma_diagonal_vector=sigma_diagonal_vector, \u001b[39;00m\n\u001b[1;32m      3\u001b[0m                         \u001b[38;5;66;03m#tau_diagonal_vector=tau_diagonal_vector, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m                         \u001b[38;5;66;03m#row_diagonal_vector=row_diagonal_vector, \u001b[39;00m\n\u001b[1;32m      5\u001b[0m                         \u001b[38;5;66;03m#column_diagonal_vector=column_diagonal_vector\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                         )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "mm = MatrixMultiplicator(d, create_zero=lambda: np.zeros(d*d), \n",
    "                        #sigma_diagonal_vector=sigma_diagonal_vector, \n",
    "                        #tau_diagonal_vector=tau_diagonal_vector, \n",
    "                        #row_diagonal_vector=row_diagonal_vector, \n",
    "                        #column_diagonal_vector=column_diagonal_vector\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0713512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56347209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hnrf.hnrf.HEDT at 0x7f804a447790>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58a4e68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b1a34b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0930588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhnrf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhnrf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HNRF\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m h_rf \u001b[38;5;241m=\u001b[39m \u001b[43mHNRF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/HNRF/hnrf/hnrf.py:114\u001b[0m, in \u001b[0;36mHNRF.__init__\u001b[0;34m(self, neural_rf, device)\u001b[0m\n\u001b[1;32m    110\u001b[0m     comparator \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(h\u001b[38;5;241m.\u001b[39mreturn_comparator())\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomparator \u001b[38;5;241m=\u001b[39m comparator\n\u001b[0;32m--> 114\u001b[0m W1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    115\u001b[0m W2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate(W2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    116\u001b[0m B2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mconcatenate(B2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "from hnrf.hnrf import HNRF\n",
    "#Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))\n",
    "h_rf = HNRF(Nmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb59ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logq = 540\n",
    "logp = 30\n",
    "logn = 14 # 질문 * Ntree\n",
    "n = 1*2**logn\n",
    "slots = n\n",
    "\n",
    "parms = Param(n=n, logp=logp, logq=logq)\n",
    "\n",
    "do_reduction=False\n",
    "\n",
    "ring = he.Ring()\n",
    "secretKey = he.SecretKey(ring)\n",
    "scheme = he.Scheme(secretKey, ring, False)\n",
    "\n",
    "algo = he.SchemeAlgo(scheme)\n",
    "\n",
    "# reduction때는 right rotation N_class개 필요. \n",
    "if do_reduction:\n",
    "    Nclass = Nmodel.head.shape[0]\n",
    "    scheme.addLeftRotKeys(secretKey)\n",
    "    for i in range(Nclass):\n",
    "        scheme.addRightRotKey(secretKey, i+1) # \n",
    "else:\n",
    "    # reduction 안 하면 하나짜리 rotation만 여러번 반복.\n",
    "    scheme.addLeftRotKey(secretKey, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ab51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3866f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fase.core import commonAlgo\n",
    "class HETreeEvaluator:\n",
    "    \"\"\"Evaluator which will perform homomorphic computation\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 b0: np.ndarray, w1, b1, w2, b2,\n",
    "                 scheme,\n",
    "                 parms,\n",
    "                 activation_coeffs: List[float], \n",
    "                 #polynomial_evaluator: Callable,\n",
    "                 \n",
    "                 #relin_keys: seal.RelinKeys, galois_keys: seal.GaloisKeys, scale: float,\n",
    "                 do_reduction=True):\n",
    "        \"\"\"Initializes with the weights used during computation.\n",
    "\n",
    "        Args:\n",
    "            b0: bias of the comparison step\n",
    "\n",
    "        \"\"\"\n",
    "        self.sk = secretKey ######### \n",
    "        self.scheme = scheme\n",
    "        self.algo = he.SchemeAlgo(scheme)\n",
    "        self.commonAlgo = commonAlgo.CommonAlgorithms(scheme, \"HEAAN\")\n",
    "        # scheme should hold all keys\n",
    "        self.parms = parms\n",
    "        \n",
    "        self._activation_coeff = activation_coeffs\n",
    "        self._activation_poly_degree = len(activation_coeffs) -1\n",
    "        self.do_reduction = do_reduction\n",
    "\n",
    "        # 10-degree activation -> up to 5 multiplications \n",
    "        logq_w1 = self.parms.logq - 5 * self.parms.logp\n",
    "        logq_b1 = logq_w1 - self.parms.logp\n",
    "        logq_b2 = logq_b1 - 5*self.parms.logp\n",
    "\n",
    "        self.b0_ctx = self.encrypt(b0)\n",
    "        self.w1 = [self.to_double(w) for w in w1]\n",
    "        self.w2 = [self.to_double(w) for w in w2]\n",
    "        \n",
    "        self.b1_ctx = self.encrypt(b1, logq=logq_b1)\n",
    "        self.b2_ctx = [self.encrypt(b, logq=logq_b2) for b in b2]\n",
    "\n",
    "        self.setup_summary()      \n",
    "    \n",
    "    def setup_summary(self):\n",
    "        print(\"CKKS paramters:\")\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"n = {self.parms.n}\")\n",
    "        print(f\"logp = {self.parms.logp}\")\n",
    "        print(f\"logq = {self.parms.logq}\")\n",
    "        print(f\"tanh activation polynomial coeffs = {self._activation_coeff}\")\n",
    "        print(f\"tanh activation polynomial degree = {self._activation_poly_degree}\")\n",
    "        \n",
    "        print(\"\\nNeural RF\")\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"\")\n",
    "    \n",
    "    def heaan_double(self, val):\n",
    "        mvec = np.zeros(self.parms.n)\n",
    "        mvec[:len(val)] = np.array(val)\n",
    "        return he.Double(mvec)\n",
    "\n",
    "    def decrypt_print(self, ctx, n=20):\n",
    "        res1 = self.decrypt(ctx)\n",
    "        print(\"_____________________\")\n",
    "        print(res1[:n])\n",
    "        print(res1.min(), res1.max())\n",
    "        print(\"---------------------\")\n",
    "\n",
    "    def decrypt(self, enc):\n",
    "        temp = self.scheme.decrypt(self.sk, enc)\n",
    "        arr = np.zeros(self.parms.n, dtype=np.complex128)\n",
    "        temp.__getarr__(arr)\n",
    "        return arr.real\n",
    "        \n",
    "    def encrypt_ravel(self, val, **kwargs):\n",
    "        \"\"\"encrypt a list\n",
    "        \"\"\"\n",
    "        return self.encrypt(np.array(val).ravel(), **kwargs)\n",
    "\n",
    "    def encrypt(self, val, n=None, logp=None, logq=None):\n",
    "        if n == None: n = self.parms.n\n",
    "        if logp == None: logp = self.parms.logp\n",
    "        if logq == None: logq = self.parms.logq\n",
    "            \n",
    "        ctxt = he.Ciphertext()\n",
    "        vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "        vv[:len(val)] = val\n",
    "        self.scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "        del vv\n",
    "        return ctxt\n",
    "    \n",
    "    def to_double(self, val):\n",
    "        n = self.parms.n\n",
    "        vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "        vv[:len(val)] = val\n",
    "        return he.Double(vv)\n",
    "        \n",
    "        \n",
    "    def activation(self, ctx):\n",
    "        output = he.Ciphertext()\n",
    "        output = he.Ciphertext()\n",
    "        self.algo.function_poly(output, \n",
    "                    ctx, \n",
    "                    he.Double(self._activation_coeff), \n",
    "                    self.parms.logp, \n",
    "                    self._activation_poly_degree)\n",
    "        return output        \n",
    "        \n",
    "\n",
    "    def __call__(self, ctx):\n",
    "        # First we add the first bias to do the comparisons\n",
    "        ctx = self.compare(ctx)\n",
    "        print(\"After compare\")\n",
    "        self.decrypt_print(ctx)\n",
    "        ctx = self.match(ctx)\n",
    "        print(\"after match\")\n",
    "        self.decrypt_print(ctx)\n",
    "        outputs = self.decide(ctx)\n",
    "        if self.do_reduction:\n",
    "            outputs = self.reduce(outputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compare(self, ctx, debug=False):\n",
    "        \"\"\"Calculate first layer of the HNRF\n",
    "        \n",
    "        ctx = featurizer.encrypt(x)\n",
    "        \n",
    "        Assuming n, logp, logq are globally available\n",
    "        \n",
    "        \"\"\"\n",
    "        b0_ctx = self.b0_ctx\n",
    "        self.scheme.addAndEqual(ctx, b0_ctx)\n",
    "        # Activation\n",
    "        output = self.activation(ctx)\n",
    "            \n",
    "        del b0_ctx, ctx\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def _mat_mult(self, diagonals, ctx):\n",
    "        \"\"\"\n",
    "        Take plain vector \n",
    "        \"\"\"\n",
    "        scheme = self.scheme\n",
    "        n = self.parms.n\n",
    "        logp = self.parms.logp\n",
    "        #logq = self.parms.logq\n",
    "\n",
    "        ctx_copy = he.Ciphertext()\n",
    "        ctx_copy.copy(ctx)\n",
    "        \n",
    "        for i, diagonal in enumerate(diagonals):\n",
    "            if i > 0: scheme.leftRotateFastAndEqual(ctx_copy, 1) # r = 1\n",
    "\n",
    "            # Multiply with diagonal\n",
    "            dd = he.Ciphertext()\n",
    "            \n",
    "            # Reduce the scale of diagonal\n",
    "            scheme.multByConstVec(dd, ctx_copy, diagonal, logp)\n",
    "            scheme.reScaleByAndEqual(dd, logp)\n",
    "            \n",
    "            if i == 0:\n",
    "                mvec = np.zeros(n)\n",
    "                temp = he.Ciphertext()\n",
    "                scheme.encrypt(temp, he.Double(mvec), n, logp, ctx_copy.logq - logp)\n",
    "            \n",
    "            # match scale \n",
    "            scheme.addAndEqual(temp, dd)\n",
    "\n",
    "            #print(\"temp\",i)\n",
    "            #self.decrypt_print(temp,10)\n",
    "            \n",
    "            del dd\n",
    "        del ctx_copy\n",
    "        return temp\n",
    "\n",
    "\n",
    "    def match(self, ctx):\n",
    "        \"\"\"Applies matching homomorphically.\n",
    "\n",
    "        First it does the matrix multiplication with diagonals, then activate it.\n",
    "        \"\"\"\n",
    "        output = self._mat_mult(self.w1, ctx)\n",
    "\n",
    "        #print(f\"MATCH:: 'output.logq', {output.logq} == {self.b1_ctx.logq}?\")\n",
    "        self.scheme.addAndEqual(output, self.b1_ctx)\n",
    "        \n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def decide(self, ctx):\n",
    "        \"\"\"Applies the decisions homomorphically.\n",
    "\n",
    "        For each class, multiply the ciphertext with the corresponding weight of that class and\n",
    "        add the bias afterwards.\n",
    "        \"\"\"\n",
    "        # ww와 bb도 미리 modDowntoAndEqual 가능 \n",
    "        outputs = []\n",
    "\n",
    "        for ww, bb in zip(self.w2, self.b2_ctx):\n",
    "            output = he.Ciphertext()\n",
    "            \n",
    "            # Multiply weights            \n",
    "            scheme.multByConstVec(output, ctx, ww, ctx.logp)\n",
    "            #print(\"ctx\", ctx)\n",
    "            #print(\"bb\", bb)\n",
    "            self.scheme.reScaleByAndEqual(output, ctx.logp)\n",
    "            \n",
    "            # Add bias\n",
    "            self.scheme.addAndEqual(output, bb)\n",
    "            \n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    def _sum_reduce(self, ctx, logn, scheme):\n",
    "        \"\"\"\n",
    "        return sum of a Ciphertext (repeated nslot times)\n",
    "        \n",
    "        example\n",
    "        -------\n",
    "        sum_reduct([1,2,3,4,5])\n",
    "        >> [15,15,15,15,15]\n",
    "        \"\"\"\n",
    "        output = he.Ciphertext()\n",
    "        \n",
    "        for i in range(logn):\n",
    "            \n",
    "            if i == 0:\n",
    "                temp = he.Ciphertext(ctx.logp, ctx.logq, ctx.n)\n",
    "                \n",
    "                scheme.leftRotateFast(temp, ctx, 2**i)\n",
    "                scheme.add(output, ctx, temp)\n",
    "            else:\n",
    "                scheme.leftRotateFast(temp, output, 2**i)\n",
    "                scheme.addAndEqual(output, temp)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def reduce(self, outputs):\n",
    "        logp = self.parms.logp\n",
    "        scheme = self.scheme\n",
    "\n",
    "        for i, output in enumerate(outputs):\n",
    "            output = self._sum_reduce(output, self.parms.logn, self.scheme)\n",
    "\n",
    "            mask = np.zeros(self.parms.n)\n",
    "            mask[0] = 1\n",
    "            mask_hedb = he.ComplexDouble(mask)\n",
    "            if i == 0:\n",
    "                scores = he.Ciphertext()\n",
    "                scheme.multByConstVec(scores, output, mask_hedb, logp)\n",
    "                scheme.reScaleByAndEqual(scores, logp)\n",
    "            else:\n",
    "                temp = he.Ciphertext()\n",
    "                scheme.multByConstVec(temp, output, mask_hedb, logp)\n",
    "                scheme.reScaleByAndEqual(temp, logp)\n",
    "                scheme.rightRotateFastAndEqual(temp, i)\n",
    "                scheme.addAndEqual(scores, temp)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_model(cls, model,\n",
    "                   scheme,\n",
    "                   parms,\n",
    "                   activation_coeffs: List[float],\n",
    "                   do_reduction=False):\n",
    "        \"\"\"Creates an Homomorphic Tree Evaluator from a model, i.e a neural tree or\n",
    "        a neural random forest. \"\"\"\n",
    "        b0, w1, b1, w2, b2 = model.return_weights()\n",
    "\n",
    "        return cls(b0, w1, b1, w2, b2, scheme, parms, activation_coeffs, do_reduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935ad25",
   "metadata": {},
   "source": [
    "## To do\n",
    "1. mat_mult만 따로 떼서 새 버전과 비교\n",
    "2. 여러개의 DT가 어떻게 하나의 weight로 합쳐지는지 이해\n",
    "3. 하나의 DT를 하나의 W로 두고 마지막에 합치는 방법 고려\n",
    "4. 최대 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9aa19c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKKS paramters:\n",
      "---------------------------\n",
      "n = 16384\n",
      "logp = 30\n",
      "logq = 540\n",
      "tanh activation polynomial coeffs = [-2.220446e-16  1.414345e+01  6.957629e-14 -6.083490e+02 -4.696993e-12  1.686577e+04  1.302394e-10 -2.740924e+05\n",
      " -1.925923e-09  2.801868e+06  1.733859e-08 -1.913169e+07 -1.026167e-07  9.105737e+07  4.185374e-07 -3.108234e+08\n",
      " -1.210472e-06  7.742619e+08  2.519760e-06 -1.418430e+09 -3.787154e-06  1.907839e+09  4.071917e-06 -1.860355e+09\n",
      " -3.053341e-06  1.278950e+09  1.516193e-06 -5.875175e+08 -4.479662e-07  1.618027e+08  5.960464e-08 -2.019733e+07]\n",
      "tanh activation polynomial degree = 31\n",
      "\n",
      "Neural RF\n",
      "---------------------------\n",
      "\n",
      "10.060018062591553 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "nrf_evaluator = HETreeEvaluator.from_model(h_rf,\n",
    "                                            scheme,\n",
    "                                            parms,\n",
    "                                            my_tm_tanh.coeffs,\n",
    "                                            do_reduction = do_reduction\n",
    "                                            )\n",
    "print(f\"{time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c3bdd",
   "metadata": {},
   "source": [
    "이거를 빨리... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = heaan_nrf.HETreeFeaturizer(h_rf.return_comparator(), scheme, parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "525aef21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After compare\n",
      "_____________________\n",
      "[-3553.537785   633.312096   986.104281  -787.331721   753.215784    17.463915  2229.890549  -523.92082    928.679984\n",
      "   485.509195 -1378.30313     90.998323    77.088115   -61.983928   -28.754441  2653.945035  -150.272121   963.285134\n",
      "  -841.769644   127.686831]\n",
      "-5333.147424207689 5691.436050251888\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[ 7.852005e+37 -1.294581e+38  2.877582e+36 -3.370628e+37 -4.385838e+37 -2.508176e+37 -7.089489e+37  3.428295e+37\n",
      " -4.342916e+36 -6.037652e+37 -5.534335e+36  6.614096e+37 -3.197613e+37  1.451282e+37  2.682505e+37  1.911827e+37\n",
      "  5.009485e+36  9.673895e+36 -6.125014e+37  3.132460e+37]\n",
      "-1.8520879702038686e+38 1.9058639152915016e+38\n",
      "---------------------\n",
      "Prediction: 4 == 1?\n",
      "[-3.71161233210469e+30, 9.307488528757506e+29, -3.2933943702326227e+30, -9.905789000637382e+30, 6.252425452385588e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "320.9232385158539 seconds\n",
      "After compare\n",
      "_____________________\n",
      "[ -235.635208  -943.15398  -1301.814741  -347.100185  -502.662327  -255.86125   2532.937989  1227.177451  -149.029126\n",
      "  -645.665919  1230.19121    491.11025   2050.2035   -1580.161547  1016.711548  1435.417943  -905.452558   105.495409\n",
      "   128.961018   103.559585]\n",
      "-5093.908634793589 6203.6942013074395\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[-4.055771e+37  2.535365e+37  1.583852e+37 -3.028829e+37  7.643601e+36 -2.762211e+37 -2.660290e+37  1.645228e+37\n",
      "  3.564637e+37  6.832426e+37  8.176236e+36 -2.653088e+37  1.251013e+37 -6.637836e+37 -3.249653e+37 -7.071146e+37\n",
      " -1.668096e+37 -9.011005e+37 -3.903279e+37 -3.546487e+37]\n",
      "-1.973649056579077e+38 1.9488920201152825e+38\n",
      "---------------------\n",
      "Prediction: 2 == 3?\n",
      "[-7.802566055601398e+30, -1.2610083974848653e+30, 9.672224523122543e+30, -8.904715054423057e+30, -2.67620991750405e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "320.7123508453369 seconds\n",
      "After compare\n",
      "_____________________\n",
      "[-2.291012e+03  1.555178e+00 -2.365029e+02 -2.945746e+02 -8.717615e+02 -1.998846e+02  9.068630e+02  1.031169e+03\n",
      " -8.930495e+01  5.945445e+02  1.325331e+03  8.752705e+02 -1.898053e+02 -4.888237e+02 -1.418128e+03  4.543078e+02\n",
      " -1.478649e+03  1.188979e+02  1.117645e+03  1.615566e+03]\n",
      "-4658.492464438119 5093.282041732371\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[-4.776948e+37  1.054919e+37 -2.219667e+37  2.016499e+37  3.214528e+37  8.093641e+37 -1.882962e+37  3.504283e+37\n",
      " -1.113077e+38  2.340546e+37  1.397401e+37  8.368155e+37 -1.823446e+37  4.566435e+37  1.489273e+37  3.228851e+37\n",
      " -1.018208e+37 -1.211039e+37  3.534537e+37  1.735513e+36]\n",
      "-2.055498606769217e+38 1.9533358152941596e+38\n",
      "---------------------\n",
      "Prediction: 1 == 3?\n",
      "[-3.8615763668015525e+30, 1.6360122624028613e+30, -1.3623950147429774e+30, -5.231040938990557e+30, -5.242254234359813e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "319.717000246048 seconds\n",
      "After compare\n",
      "_____________________\n",
      "[ 1211.115754    76.620439   150.900549   484.705791  -233.436832  -126.717039 -1122.413874 -1415.565451 -1028.147394\n",
      "   492.720089  -438.530197   288.569848 -1641.897741  -314.865551  -382.59461    528.816216   217.738591  -272.827607\n",
      "  -786.363107  -494.700473]\n",
      "-6162.405257997043 6042.010955123566\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[-5.137252e+37 -2.193313e+37  5.922886e+37 -6.845646e+37  1.585388e+37 -7.454759e+37 -1.310100e+37 -1.009898e+38\n",
      " -7.560860e+36 -2.018796e+36 -8.043519e+37  9.553839e+37  7.409157e+37  2.947659e+37 -3.847537e+37 -9.590151e+37\n",
      "  4.482262e+37  2.657899e+37  1.519527e+37  5.519570e+37]\n",
      "-2.045343284220147e+38 1.9666144794302594e+38\n",
      "---------------------\n",
      "Prediction: 1 == 1?\n",
      "[-3.260089917015278e+30, 7.599506198344162e+30, 4.904356006601706e+30, -8.460971521090669e+30, 4.090724259997935e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "321.088018655777 seconds\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in zip(X_valid[:4], y_valid[:4]):\n",
    "    t0 = time()\n",
    "    #print(len(xx))\n",
    "    ctx = featurizer.encrypt(xx)\n",
    "    result = nrf_evaluator(ctx)\n",
    "    #print(f\"Took {time() - t0:.2f} seconds\")\n",
    "\n",
    "    pred = []\n",
    "    for res in result:\n",
    "        dec = decrypt(secretKey, res)\n",
    "        pred.append(np.sum(dec))\n",
    "\n",
    "    print(f\"Prediction: {np.argmax(pred)} == {yy}?\") \n",
    "    neural_pred = Nmodel(torch.tensor(X_train[:1]).float())\n",
    "    print(pred)\n",
    "    print(neural_pred)\n",
    "    print(f\"{time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "104d1fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887150053714814"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b58f07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pred = Nmodel(torch.tensor(X_train[:1]).float())\n",
    "#Nmodel(torch.tensor(X_valid[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3891e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -68.3079,  -4021.2930, -13188.7412,  24814.9121, -10345.2754]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d66646",
   "metadata": {},
   "source": [
    "여기서 만든 h_rf와 새로 만든 h_rf의 모양, 값 차이 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0bd8e",
   "metadata": {},
   "source": [
    "min = 0, \n",
    "max = 1인데.. 왜 -1보다 작아질까...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "912b3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1354.7771911621098,\n",
       " -657.0239105224605,\n",
       " -13200.904769897461,\n",
       " 19254.122360229492,\n",
       " -9825.276138305662]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22183461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
