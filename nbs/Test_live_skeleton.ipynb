{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b896c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#from fase.core import heaan\n",
    "\n",
    "from fase import HEAAN\n",
    "from fase import HEAAN as he\n",
    "from typing import List, Callable\n",
    "\n",
    "from fase import hnrf as hnrf\n",
    "\n",
    "from fase.hnrf.tree import NeuralTreeMaker\n",
    "from fase.hnrf import heaan_nrf\n",
    "from fase.hnrf.hetree import HomomorphicModel\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52809e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "min max of input dataset\n",
      "0.0 1.0000000000000002\n",
      "0.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/home/hoseung/Work/Kinect_BBS_demo/nbs/\"\n",
    "\n",
    "CAM_LIST= {1: \"e\",\n",
    "           2: \"e\",\n",
    "           3: \"a\",\n",
    "           4: \"e\",\n",
    "           5: \"e\",\n",
    "           6: \"e\",\n",
    "           7: \"e\",\n",
    "           8: \"a\",\n",
    "           9: \"a\",\n",
    "           10:\"e\",\n",
    "           11:\"e\",\n",
    "           12:\"e\",\n",
    "           13:\"a\",\n",
    "           14:\"e\"}\n",
    "#for action in np.arange(1,15): \n",
    "# 3, 9는 아직 없음 , 12번 다시. \n",
    "action = 1\n",
    "cam = CAM_LIST[action]\n",
    "\n",
    "\n",
    "fn_model_out = f\"trained_model_{action}_{cam}.pickle\"\n",
    "fn_data_out = f\"BBS_dataset_{action}_{cam}.pickle\"\n",
    "\n",
    "fn_model = model_dir + fn_model_out\n",
    "fn_dat = model_dir + fn_data_out\n",
    "\n",
    "rf_model = pickle.load(open(fn_model, \"rb\"))\n",
    "\n",
    "print(\"model's depth:\", rf_model.max_depth)\n",
    "print(\"model's tree count:\", rf_model.n_estimators)\n",
    "\n",
    "\n",
    "#####\n",
    "dataset = pickle.load(open(fn_dat, \"rb\"))\n",
    "\n",
    "X_train = dataset[\"train_x\"]\n",
    "y_train = dataset[\"train_y\"]\n",
    "X_valid = dataset[\"valid_x\"]\n",
    "y_valid = dataset[\"valid_y\"]\n",
    "\n",
    "print(\"min max of input dataset\")\n",
    "print(X_train.min(), X_train.max())\n",
    "print(X_valid.min(), X_valid.max())\n",
    "\n",
    "#####\n",
    "from sklearn.tree import BaseDecisionTree\n",
    "from fase.hnrf.tree import NeuralRF\n",
    "\n",
    "dilatation_factor = 10\n",
    "polynomial_degree = 10\n",
    "\n",
    "estimators = rf_model.estimators_\n",
    "\n",
    "my_tm_tanh = NeuralTreeMaker(torch.tanh,\n",
    "                            use_polynomial=True,\n",
    "                            dilatation_factor=dilatation_factor,\n",
    "                            polynomial_degree=polynomial_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c214cf",
   "metadata": {},
   "source": [
    "성능 확실함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b5698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.9149659863945578\n",
      "Accuracy : 0.9421768707482994\n",
      "Same output : 0.9136054421768708\n"
     ]
    }
   ],
   "source": [
    "from fase.hnrf.hetree import HNRF\n",
    "action = 1\n",
    "cam = CAM_LIST[action]\n",
    "Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))\n",
    "\n",
    "fn_model_out = f\"trained_model_{action}_{cam}.pickle\"\n",
    "fn_data_out = f\"BBS_dataset_{action}_{cam}.pickle\"\n",
    "fn_dat = model_dir + fn_data_out\n",
    "fn_model = model_dir + fn_model_out\n",
    "\n",
    "rf_model = pickle.load(open(fn_model, \"rb\"))\n",
    "\n",
    "#####\n",
    "dataset = pickle.load(open(fn_dat, \"rb\"))\n",
    "\n",
    "X_train = dataset[\"train_x\"]\n",
    "y_train = dataset[\"train_y\"]\n",
    "X_valid = dataset[\"valid_x\"]\n",
    "y_valid = dataset[\"valid_y\"]\n",
    "\n",
    "\n",
    "pred = rf_model.predict(X_valid)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_valid).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_valid).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_valid).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")\n",
    "\n",
    "\n",
    "h_rf = HNRF(Nmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2fe2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading secret key done.\n",
      "HEAAN CKKS setup is ready \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.00000019e+00,  3.00000125e+00,  4.00000080e+00, ...,\n",
       "        3.49577530e-07, -1.83688058e-06,  1.00000497e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logq = 540\n",
    "logp = 30\n",
    "logn = 14\n",
    "n = 1*2**logn\n",
    "slots = n\n",
    "\n",
    "\n",
    "do_reduction=False\n",
    "\n",
    "from fase.core.common import HEAANContext\n",
    "\n",
    "logq = 540\n",
    "logp = 30\n",
    "logn = 14\n",
    "hec = HEAANContext(logn, logp, logq, rot_l=[1],\n",
    "                   key_path=\"/home/hoseung/Work/Kinect_BBS_demo/serkey/\",\n",
    "                   FN_SK=\"secret.key\",\n",
    "                   boot=False,\n",
    "                   is_owner=True,\n",
    "                   load_sk=True\n",
    "                  )\n",
    "\n",
    "cc = hec.encrypt([1,2,3,4])\n",
    "dd = hec.lrot(cc, 1)\n",
    "hec.decrypt(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0229b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKKS paramters:\n",
      "---------------------------\n",
      "n = 16384\n",
      "logp = 30\n",
      "logq = 540\n",
      "tanh activation polynomial coeffs = [-1.16068771e-16  4.75814899e+00  3.30039026e-15 -1.83821464e+01\n",
      " -2.46267653e-14  3.86047910e+01  6.66941250e-14 -3.72804331e+01\n",
      " -7.36380653e-14  1.33120796e+01  2.84217094e-14]\n",
      "tanh activation polynomial degree = 10\n",
      "\n",
      "Neural RF\n",
      "---------------------------\n",
      "\n",
      "[EVAL.model_loader] HNRF model loaded for class 1 in 10.88 seconds\n",
      "Prediction: 3 == 3?\n",
      "[-0.5832366943359376, -0.8536071777343749, 0.30851745605468744, 1.4260406494140627, 1.2083587646484377]\n",
      "tensor([[-0.5825, -0.8535,  0.3087,  1.4260,  1.2085]], grad_fn=<AddBackward0>)\n",
      "244.58722138404846 seconds\n",
      "Prediction: 4 == 4?\n",
      "[-0.575836181640625, -0.41778564453124983, -1.146728515625, 1.0041961669921875, 3.158004760742188]\n",
      "tensor([[-0.5754, -0.4176, -1.1464,  1.0041,  3.1581]], grad_fn=<AddBackward0>)\n",
      "246.3609013557434 seconds\n",
      "Prediction: 2 == 2?\n",
      "[1.1198425292968752, -0.3457336425781249, 3.0722045898437496, 0.5701141357421875, -3.424896240234375]\n",
      "tensor([[ 1.1205, -0.3455,  3.0724,  0.5699, -3.4249]], grad_fn=<AddBackward0>)\n",
      "249.59111952781677 seconds\n",
      "Prediction: 4 == 3?\n",
      "[-0.7433319091796876, -1.3285064697265625, 1.0275573730468748, 1.2269897460937498, 1.2563934326171875]\n",
      "tensor([[-0.7428, -1.3283,  1.0278,  1.2269,  1.2566]], grad_fn=<AddBackward0>)\n",
      "248.9566068649292 seconds\n",
      "Prediction: 0 == 0?\n",
      "[2.634323120117187, 0.4631195068359371, -1.621063232421875, -0.8802337646484373, 0.6472015380859377]\n",
      "tensor([[ 2.6348,  0.4632, -1.6208, -0.8801,  0.6473]], grad_fn=<AddBackward0>)\n",
      "236.9761712551117 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119500/3977030237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#print(len(xx))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencrypt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnrf_evaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m#print(f\"Took {time() - t0:.2f} seconds\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/heaan_nrf.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m#print(\"After compare\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m#self.decrypt_print(ctx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;31m#print(\"after match\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m#self.decrypt_print(ctx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/heaan_nrf.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mFirst\u001b[0m \u001b[0mit\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mmultiplication\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdiagonals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mactivate\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \"\"\"\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mat_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m#print(f\"MATCH:: 'output.logq', {output.logq} == {self.b1_ctx.logq}?\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/heaan_nrf.py\u001b[0m in \u001b[0;36m_mat_mult\u001b[0;34m(self, diagonals, ctx)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m#print(\"logq in mat_mult\", diagonal.logq, ctx_copy.logq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;31m#scheme.modDownToAndEqual(diagonal, ctx.logq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleftRotateFastAndEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# r = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Multiply with diagonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#server_path = \"/home/hoseung/Work/Kinect_BBS_demo/server/\"\n",
    "t0 = time()\n",
    "\n",
    "my_tm_tanh = NeuralTreeMaker(torch.tanh,\n",
    "             use_polynomial=True,\n",
    "             dilatation_factor=10,\n",
    "             polynomial_degree=10)\n",
    "\n",
    "nrf_evaluator = heaan_nrf.HETreeEvaluator(h_rf,\n",
    "                                          hec._scheme,\n",
    "                                          hec.parms,\n",
    "                                          my_tm_tanh.coeffs,\n",
    "                                          do_reduction = False,\n",
    "                                          sk=hec.sk\n",
    "                                          )\n",
    "print(f\"[EVAL.model_loader] HNRF model loaded for class {action} in {time() - t0:.2f} seconds\")\n",
    "\n",
    "\n",
    "featurizer = heaan_nrf.HETreeFeaturizer(h_rf.return_comparator(), hec._scheme, hec.parms)\n",
    "\n",
    "for xx, yy in zip(X_valid[:9], y_valid[:9]):\n",
    "    t0 = time()\n",
    "    #print(len(xx))\n",
    "    ctx = featurizer.encrypt(xx)\n",
    "    result = nrf_evaluator(ctx)\n",
    "    #print(f\"Took {time() - t0:.2f} seconds\")\n",
    "\n",
    "    pred = []\n",
    "    for res in result:\n",
    "        dec = hec.decrypt(res)\n",
    "        pred.append(np.sum(dec))\n",
    "\n",
    "    print(f\"Prediction: {np.argmax(pred)} == {yy}?\")\n",
    "    neural_pred = Nmodel(torch.tensor(xx.reshape(1,-1)).float())\n",
    "    print(pred)\n",
    "    print(neural_pred)\n",
    "    print(f\"{time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225f54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9752d7df",
   "metadata": {},
   "source": [
    "## Live skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "421b183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0 == 0?\n",
      "[300170.0118865967, -258487.78353881833, 100222.64962768552, 88093.27374267581, -263934.35498046875]\n",
      "tensor([[ 2.6348,  0.4632, -1.6208, -0.8801,  0.6473]], grad_fn=<AddBackward0>)\n",
      "2499.2437810897827 seconds\n"
     ]
    }
   ],
   "source": [
    "ctx_live = he.Ciphertext(hec.parms.logp, hec.parms.logq, hec.parms.n)\n",
    "he.SerializationUtils.readCiphertext(ctxt, \"/home/hoseung/Work/Kinect_BBS_demo/ctx_01_e_.dat\")\n",
    "\n",
    "ddl = hec.decrypt(ctx_live)\n",
    "\n",
    "result = nrf_evaluator(ctx_live)\n",
    "pred = []\n",
    "for res in result:\n",
    "    dec = hec.decrypt(res)\n",
    "    pred.append(np.sum(dec))\n",
    "\n",
    "print(f\"Prediction: {np.argmax(pred)} == {yy}?\")\n",
    "neural_pred = Nmodel(torch.tensor(xx.reshape(1,-1)).float())\n",
    "print(pred)\n",
    "print(neural_pred)\n",
    "print(f\"{time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac05fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scsc = pickle.load(open(\"/home/hoseung/Work/Kinect_BBS_demo/scaled.pickle\", \"rb\"))\n",
    "skeleton = pickle.load(open(\"/home/hoseung/Work/Kinect_BBS_demo/skeleton_org.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03423d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456,  0.24298629,\n",
       "        -1.09259172,  0.12157011, -0.08555162,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456,  0.23584416,\n",
       "        -1.07830746,  0.15013862, -0.106978  ,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456, -3.99229585,\n",
       "        -3.99229585, -3.99229585, -3.99229585,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456, -3.99229585,\n",
       "        -3.99229585, -3.99229585, -3.99229585,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456,  0.19299139,\n",
       "        -1.05688108,  0.15013862, -0.21410993,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456,  0.15013862,\n",
       "        -1.08544959,  0.10014372, -0.19268354,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456,  0.28583906,\n",
       "        -1.10687598,  0.14299649, -0.18554141,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957,\n",
       "         0.72150889, -0.03555672,  0.82149869, -0.50693719,  0.65008761,\n",
       "        -1.164013  , -0.16411503, -1.22115003, -0.37837888, -0.69263253,\n",
       "        -0.33552611, -0.16411503,  0.26441268, -1.80680456,  0.27869693,\n",
       "        -1.19972364,  0.26441268, -0.19982567,  0.53581355,  1.07861531,\n",
       "         0.79293018,  0.63580335,  0.37868673, -0.14983077, -0.0069882 ,\n",
       "        -0.13554651, -0.17839928,  0.76436166, -0.13554651,  1.09289957]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f33373da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/newbbs/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/hoseung/anaconda3/envs/newbbs/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from bbsQt.model.data_preprocessing import shift_to_zero, measure_lengths\n",
    "\n",
    "skeleton = shift_to_zero(skeleton)\n",
    "\n",
    "body = measure_lengths(skeleton)\n",
    "skeleton /= body['body'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2a38444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.696233  , 0.69421952, 0.67685089, 0.47663497, 0.5587459 ,\n",
       "       0.27276982, 0.44043189, 0.29356282, 0.42521834, 0.34671189,\n",
       "       0.38878078, 0.50491765, 0.46669831, 0.03897981, 0.45340473,\n",
       "       0.33419445, 0.4282126 , 0.45429762, 0.707601  , 0.29691936,\n",
       "       0.79521291, 0.47682256, 0.53188586, 0.3973425 , 0.46123211,\n",
       "       0.40223002, 0.44142657, 0.64079501, 0.46786661, 0.25487306,\n",
       "       0.91094498, 0.88601657, 0.92805861, 0.88943895, 0.95238095,\n",
       "       0.87281615, 0.87735984, 0.87073649, 0.84870234, 0.88763796,\n",
       "       0.86514708, 0.87936936, 0.92908786, 0.79906745, 0.93248708,\n",
       "       0.8830863 , 0.898176  , 0.91794101, 0.90732092, 0.88943381,\n",
       "       0.94667386, 0.92463759, 0.90287495, 0.91429728, 0.88261675,\n",
       "       0.91528238, 0.89154579, 0.93011361, 0.8903384 , 0.88914308,\n",
       "       0.85856091, 0.88158684, 0.8278053 , 0.863766  , 0.81593305,\n",
       "       0.82837953, 0.7794648 , 0.82393085, 0.7506356 , 0.84565169,\n",
       "       0.76281667, 0.85800608, 0.82893661, 0.72583209, 0.38738685,\n",
       "       0.48035824, 0.38999828, 0.43763452, 0.82451648, 0.86870519,\n",
       "       0.84487675, 0.9047264 , 0.80286991, 0.87023675, 0.79320703,\n",
       "       0.87426097, 0.76564382, 0.91623531, 0.76569553, 0.86008655,\n",
       "       0.86175186, 0.86559944, 0.83976642, 0.86057991, 0.83195064,\n",
       "       0.83763883, 0.78948119, 0.835829  , 0.77452665, 0.8391926 ,\n",
       "       0.81527197, 0.84596807, 0.83697085, 0.7407691 , 0.39678868,\n",
       "       0.5061292 , 0.39786351, 0.45779646, 0.82461527, 0.87250126,\n",
       "       0.85694366, 0.91692082, 0.81678763, 0.8681256 , 0.79866023,\n",
       "       0.86965098, 0.7837848 , 0.92044671, 0.78588968, 0.87059113,\n",
       "       0.86045368, 0.84801164, 0.82699108, 0.86184685, 0.81952296,\n",
       "       0.83097426, 0.79953899, 0.84499755, 0.79507899, 0.85742042,\n",
       "       0.80464621, 0.85234129, 0.84563848, 0.74901244, 0.80401484,\n",
       "       0.8556498 , 0.7912628 , 0.88146116, 0.81393219, 0.88394399,\n",
       "       0.83994337, 0.91019163, 0.7955414 , 0.88956324, 0.79338043,\n",
       "       0.88712545, 0.77509923, 0.92149121, 0.77653617, 0.88520852,\n",
       "       0.87135442, 0.87510504, 0.85758066, 0.87643608, 0.85068802,\n",
       "       0.85800768, 0.81181654, 0.85346461, 0.80065628, 0.86316177,\n",
       "       0.82436957, 0.87558601, 0.85853701, 0.77931562, 0.82354495,\n",
       "       0.86877835, 0.81913987, 0.88317842, 0.84491817, 0.88436972,\n",
       "       0.86904113, 0.92841431, 0.83539876, 0.8890766 , 0.79582819,\n",
       "       0.88648553, 0.75505318, 0.93728187, 0.70941109, 0.89159285,\n",
       "       0.88227576, 0.86002818, 0.86500607, 0.85019405, 0.87024287,\n",
       "       0.83220963, 0.84247523, 0.85202083, 0.82387817, 0.84218895,\n",
       "       0.83187012, 0.84012304, 0.87942759, 0.77342814, 0.86029708,\n",
       "       0.85184007, 0.84488795, 0.91122642, 0.84928248, 0.89010846,\n",
       "       0.88401227, 0.93309781, 0.85376575, 0.91569728, 0.84233139,\n",
       "       0.91485907, 0.83254115, 0.95000234, 0.8125037 , 0.89127446,\n",
       "       0.89497645, 0.86907314, 0.87795104, 0.87803725, 0.8653226 ,\n",
       "       0.87145165, 0.87202235, 0.87082251, 0.83906928, 0.89093698,\n",
       "       0.82600646, 0.88967372, 0.86904622, 0.79232601, 0.87197999,\n",
       "       0.87458761, 0.87071712, 0.92125301, 0.87900424, 0.8878171 ,\n",
       "       0.90313559, 0.93264818, 0.86126971, 0.92658506, 0.86500088,\n",
       "       0.92680919, 0.85450369, 0.94772331, 0.85070556, 0.88158321])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scsc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009cd674",
   "metadata": {},
   "source": [
    "# 두 skeleton의 분포 차이 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b015863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([39.,  0.,  1.,  1., 19.,  8.,  0., 14., 62., 96.]),\n",
       " array([-4.55537100e-06,  9.46636480e-02,  1.89331851e-01,  2.84000055e-01,\n",
       "         3.78668258e-01,  4.73336462e-01,  5.68004665e-01,  6.62672868e-01,\n",
       "         7.57341072e-01,  8.52009275e-01,  9.46677479e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD5CAYAAADP2jUWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbwElEQVR4nO3db4wc9Z3n8fdnMWR1JgiM/4QwNmNjry3biIgMBgsJOWLBMMnhPAiRrZNgI5BFNGgj3YNkIp1I2D20kxWKEuIkyIoRjlaYRXsLthJ7iM+SxeYBsWc4TMa5OHZggv+t/0Di4MvKwbPfe1A1drvdPdM93V39pz4vqdXdVdXV367v1Ld/8+uqXykiMDOzfPmLZgdgZmbZc/E3M8shF38zsxxy8TczyyEXfzOzHHLxNzPLoWnNDgBg5syZ0d3d3ewwDBgeHj4dEbPqsS7ntTlGR0c5c+YM06ZNY9myZQAMDw+/D/wfoBsYBb4YEb8HkPR14FFgDPjbiHhtsvdwbltDLftrSxT/7u5uhoaGmh2GAZJ+V691Oa/N8frrr3P11Vfz8MMPX9j+ks4DuyJiQFI/0A98TdJSYC2wDPgk8L8l/VVEjE30Hs5ta6hlf3W3j1mHufvuu5kxY0bx5GuBzenjzcDn08drgJci4lxEvAscAlZkEKY1WUu0/K3+uvt/OuH809u/w3/5933Mnj2bkZERAD744AOARZIOUoeuAWuMyXI7OvDZUpOnRcRxgIg4Lml2Ov1G4I2C5Y6k0yxjk+UVyuZ2Stzyz6mrb/lrBgcHL5k2MDAA8GFELAJ2kXQNUNQ1cD/wA0lXZBqwNYpKTCs55ouk9ZKGJA2dOnWqwWFZo7n459Rfzl1+WdfA1q1bAd5Pn7proLOcl3QDQHp/Mp1+BJhbsFwXcKzUCiJiY0T0RETPrFl1OSbAmsjF3y44ceIEwEeQdA0AhV0DhwsWdddA+/kD8Ej6+BFga/p4G7BW0sckzQcWAXuyD8+y5j5/q0RVXQPAeoB58+Y1MiYrY926dezevZvTp0/T1dXFU089BXAcuFfSo8B7wEMAEbFf0svAr4DzQN9kR/pYZ3DxtwvmzJnDmTNnroTaugaAjQA9PT0eL7wJtmzZctm0xx57bCwi7im1fEQ8DTzd6Listbj4t6FKjgqYigcffJBnnnnm+vRpcdfAi5K+TXIsuLsGzNqc+/xz6tS2f2TlypUcOHCArq4uNm3aRH9/P8A16aGe9wIDkHQNAONdA4O4a8Cs7bnln1OzHvxquWOGfxMRPcUT3TVg1lnc8jczyyEXfzOzHHLxNzPLIRd/M7MccvE3M8shF38zsxxy8TczyyEXfzOzHPJJXmZmDdaoIVlq4Za/mVkOueVv1kJasYVoncktfzOzHHLxNzPLIRd/M7McqqnPX9Io8CEwBpyPiB5JM4B/BrqBUeCLEfH72sI0M7N6qkfL/zMR8amCMeD7gV0RsQjYlT43M7MW0ohunzXA5vTxZuDzDXgPMzOrQa3FP4CfSRqWtD6dNicijgOk97NrfA8zM6uzWo/zvysijkmaDeyU9OtKX5h+WawHmDdvXo1hmFkl/Dudjaup5R8Rx9L7k8ArwArghKQbANL7k2VeuzEieiKiZ9asWbWEYWbV8e90NvXiL2m6pI+PPwbuA0aAbcAj6WKPAFtrDdKyJ2lU0i8lvSVpKJ02Q9JOSQfT++uaHafVhX+ny6FaWv5zgJ9L2gfsAX4aEYPAAHCvpIPAvelza09uIXYe/05nQA19/hHxDnBrienvA/fUEpS1rDXAqvTxZmA38LVmBWNT4t/pDPAZvlaeW4gdyL/T2TgXfyvnroi4DXgA6JN0dyUvkrRe0pCkoVOnTjU2QquKf6ezQh7S2UoqbCFKuqSFGBHHy7UQI2IjsBGgp6cnsozZJjUHeEUSJPv+ixExKGkv8LKkR4H3gIeaGKNlpGWLfyXjmo8OfDaDSPInbRX+RUR8WNBC/DsuthAHcAux7fh3OivUssXfmsotRLMO5+Jvl3EL0azzufibWc3cTdt+XPwtUy4SZq3Bh3qameWQi7+ZWQ65+JuZ5ZCLv5lZDrn4m5nlkIu/mVkOufibmeWQi7+ZWQ65+JuZ5ZCLv5lZDrn4m5nlkIu/mVkOufibmeWQi7+ZWQ55SOcWU8mQx2ZmtXLL38wsh9zyz5hb9ma18QWB6sPFH/8x2cTq9ffhL/7O1K55bVjxl3Q/8F3gCuBHETHQqPey7Divncl5La1dC3slGlL8JV0BfB+4FzgC7JW0LSJ+1Yj3y4L/O+jMvFpn5tX76+Qa1fJfARyKiHcAJL0ErAHa9o+pEp3cSkhlktd23HHbPPfeX3OoUcX/RuBwwfMjwB2FC0haD6xPn56VdKBoHTOB0xO9ib5VY5SNMWncraJo+43HfdMEL8kkr5VoQu7bNa+QxF5TXmHS3Hp/zUDBNqxkf51Qo4q/SkyLS55EbAQ2ll2BNBQRPfUOrNE6PG7ntQ2lsXdPtEiJaXHZhAly267bJ89xN+o4/yPA3ILnXcCxBr2XZcd57UzOaw41qvjvBRZJmi/pKmAtsK1B72XZcV47k/OaQw3p9omI85KeAF4jOXTs+YjYX+VqynYdtLiOjdt5bVsTxu68tqWa41bEZV17ZmbW4Ty2j5lZDrn4m5nlUFOLv6T7JR2QdEhSf4n5kvRsOv9tSbc1I85iFcS9StIZSW+ltyebEWcxSc9LOilppMz8um1v5zZbWeXWec1Ow3MaEU25kfyw9FtgAXAVsA9YWrRML7CD5DjkO4FfNCveKuNeBfyk2bGWiP1u4DZgpMz8umxv57Z1cgs8D5wERktt7/T5s8Ah4G3gNue1NW6N3l8nbfmX+vaRNEPSTkkH0/vrCuZ9Pf0mOiBp9QSrvnBKeUT8GRg/pbzQGuDHkXgDuFbSDZPF3GCVxN2SIuJ14IMJFqnX9nZuMzZBbl8A7geuofT2fgBYlN7WAz+c4G2c1ww1en+tpNvnBZI/nkL9wK6IWATsSp8jaSnJMcLL0tf8QMmgUaWUOqX8xiksk7VKY1opaZ+kHZKWZRNazeq1vZ3bFlFQQKZR+rNVU0Cc19ZS07aetPiX+fZZA2xOH28GPl8w/aWIOBcR75L8K7mizKorOaW8otPOM1ZJTG8CN0XErcD3gFcbHVSd1Gt7O7etp9xnq6aAOK+tpaZtXdFx/pK6SfrDlqfP/xAR1xbM/31EXCdpA/BGRPxTOn0TsCMi/qXEOlcC34yI1TNnzozu7u5KY7YGGh4e/jAirgFQMnDXqog4Xs06xnN7/fXX3+e8Nt+5c+cYGRkJ4L9FxBa4mFvgR8A/RMTP0+m7gK9GxHDxeiQNAF8GDk6fPv3TS5YsyeojWBm17K/1PsO3mm+iW4FVkt6eN28eQ0NDdQ7FpkJSSBLJqI5nqi38qb3Aou7ubue1BYyOjjJ//vyPgIeVDNd8IbeSqhnX538AXwQeWrJkyTvObfPVsr9OtfifkHRD+sdzA8nRBFDFAFER8Zyk94DvzJo1a4phWAOcI+mu+xPwpamsIC4OF5DvAdNby38C73B5brcBTxR/KZRaQVw6DIS1hinvr1Mt/tuAR4CB9H5rwfQXJX0b+CTJEQR7yq0kIrYD23t6eprdJ9hxarggyntRhyFuI2J7T0/bjZTbFibLbWFe161bx+7duwE+RvKb3DeAK4EeYAjYTnLIYEUFxPtsy5ny/jpp8Ze0haRvcGb6L+I3SIr+y5IeBd4DHgKIiP2SXia5AtB5oC8ixqYSmJnVbsuWLQBIerNUkYjkR7++rOOy5pu0+EfEujKz7imz/NPA07UEZWZmjeWxfczMcsjF38wsh1z8zcxyyMU/p05v/w6zZ89m+fLlF6Z98MEHkFzOr5Yxm8ysDbj459TVt/w1g4ODl0wbGBgA+LDGMZvMrA24+OfUX85dzowZMy6ZtnXrVoD306dTHbPJzNqAi79dcOLECYCPANKzPGens1pxpEYzq4GLv1Wi4jGbJK2XNCRp6NSpUw0Oy8ymysXfLpgzZw4kp/5Tw5hNGyOiJyJ6PGaTWety8bcLHnzwQYDr06fFYzatlfQxSfOZZMwmM2t99R7S2TJQyaBtkzm17R9Zufk3nD59mq6uLp566in6+/t55plnrpF0EI/ZZNbRXPxzataDXy03qudvygwA5jGbzDqIu33MzHLIxd/MLIdc/M3McsjF38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsjF38wsh1z8zTrY4OAgixcvBlguqb94vqRVks5Ieiu9PZl9lNYMNY3tI2kU+BAYA85HRI+kGcA/A93AKPDFiPh9bWGaWbXGxsbo6+tj586d3HzzzfuBdZK2RcSvihb9t4j4XDNitOapR8v/MxHxqYLBwPqBXcXXgTWzbO3Zs4eFCxeyYMECSC6+8xLJJTnNGtLts4bk+q9w6XVgzSxDR48eZe7cwmvwlL385kpJ+yTtkLQsm+is2Wot/gH8TNKwpPXptDnp9V+LrwNrZhmKKHmlzeKJbwI3RcStwPeAV8utz5fo7Cy1Fv+7IuI24AGgT9Ldlb7Qf0hmjdXV1cXhw4cvmUTR5Tcj4o8RcTZ9vB24UtLMUuvzJTo7S03FPyKOpfcngVeAFcCJ9PqvxdeBLX6t/5DMGuj222/n4MGDvPvuuwAC1pJckvMCSZ+QpPTxCpKa8H7WsVr2plz8JU2X9PHxx8B9wAjJH9cj6WKF14G1NiJpVNIv08P/htJpMyTtlHQwvb+u2XFaedOmTWPDhg2sXr0aYBnwcnpJzsclPZ4u9gVgRNI+4FlgbZTpL7LOUsuhnnOAV9JGwzTgxYgYlLQXeFnSoxRcB9ba0mci4nTB8/EjuQbSY8b7ga81J7TOVI/rMxfq7e2lt7cXSSPppTiJiOfG50fEBmBDXd/U2sKUi39EvAPcWmL6+8A9tQRlLWsNsCp9vBnYjYu/WVvyGb5Wjo/kMutgNZ3hax3trog4Jmk2sFPSryt5UfpFsR5g3rx5jYzPzGrQssW/kr7P0YHPZhBJPhUeySXpkiO5IuJ4uSO5ImIjsBGgp6fHPxyatSh3+9hlfCSXWedr2Za/NZWP5DLrcC7+dhkfyWXW+Vz8LVP+LcesNbjP38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsjF38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsgDu5llpN4XZzerhYt/i3GBMLMsuNvHzCyHGtbyl3Q/8F3gCuBHETHQqPfKgsehT3RaXjvd4OAgX/nKVwCWS+ovzpeSy7V9F+gF/gT8TUS8mX2klrWGFH9JVwDfB+4FjgB7JW2LiF814v1qlWVXSzt363RiXjv5C3tsbIy+vj527tzJzTffvB9YVyJfDwCL0tsdwA/Te+twjWr5rwAOpZcDRNJLwBqgJYuEVaxl8trOX6JZ2bNnDwsXLmTBggUAAZTK1xrgxxERwBuSrpV0Q0Qczz5iy1Kjiv+NwOGC50fIQWsiBwUpl3ltV0ePHmXu3LmFk0rlq1RObwRc/Dtco4q/SkyLSxaQ1gPr06dnJR0oWn4mcHrCN/nWlONrpEnjbhVF22887psmekmJaW2d1yrfqy1yW/CZrgOu2bRp0//jYl6jePESqyheJlnw0tyekzRSW6RN1xb5nMTiqb6wUcX/CFDY5OgCjhUuEBEbgY3lViBpKCJ6GhNe43R43LnNK7Rf7JJWAt8Ero+IbklfpyhfVJDTcYW5bbdtUUqnfIapvrZRh3ruBRZJmi/pKmAtsK1B72XZcV7by16SH3KvmiBf24CHlbgTOOP+/nxoSMs/Is5LegJ4jeSQwOcjYn8j3suy47y2l4J8/Svwf0nzJenxdP5zwHaSwzwPkRzq+aVmxWvZathx/hGxneQPa6rKdh20uI6OO8d5hTaMPSK2S/rbtMtmfNpzBY8D6JvCqttuW5SQ68+gJPdmZpYnHt7BzCyHmlr8Jd0v6YCkQ5L6S8yXpGfT+W9Luq0ZcRarIO5Vks5Ieiu9PdmMOItJel7SyXKH6NVzezu32WpEbts1h8XaNafjGrbfRkRTbiQ/GP4WWABcBewDlhYt0wvsIDkW+U7gF82Kt8q4VwE/aXasJWK/G7gNGCkzvy7b27lt/9y2aw47KaeNyu34raqWf52/gS4MFRARf+biqeeFLpx6HhFvANdKuqGamBugkrhbUkS8DnxQap6k54H/BSwvtb2d29Y2UW5T1W7vds1hsbbN6bgG5BaovtvnBeD+CeYXDhK1nmSQqHLKnVZe7TJZqzSmlZL2SdohaVk2odXkBZLjwj8qmFb42Zzbi1o6t2Uaad3Af5d0UNJO4N9JP5ukr6df6gckrU6Xb9ccFuuInE5iSnmoqvjX+RuoktPKKz71PEOVxPQmcFNE3Ap8D3i10UHVKs3t+VKz0nvnNtEOuX2ByxtpC4GhiFgE7CIZ7iEkLSU5+WtZ+pofKBm9tV1zWKxTcjqRKeWh3j/4VvMNVMlp5RWfep6hSoY4+GNEnE0fbweulDQzuxCn7DhwZcHzws/m3NIeuS3TSLseeDt9vBn4JMlnWwO8FBHnIuJdkpO9VtC+OSzWETmdxJTyUPVx/pK6SX4cWV5i3k+Bf4iIn6fPdwFfjYjhEss+TnIRiQPTp0+/ZcmSJVXFYfV37tw5RkZGguRHsjuAZyNiBVSeW10c/OuW6dOnX+W8Nse5c+c4dOgQy5YlPRjDw8MAgyQ/Dt4B/DwipknaALwREf8EIGkTyY+HrwK/Ae4BjpJ0Cf4r8F8Bpk+f/mnntvmGh4dPA38DPMHF3F7YbydS7zN8qxkk6jlJ7wHfWbJkCUNDUx6fyOpkdHSU+fPn/yelT/WvKLeRDv4lqXfJkiU/dV6bY3R0lM997nMX9itJY8A7XMztn9JFS3YZROmhPJ6WdAJgyZIln3Zum0/S75jiEB317vapapCoiNgeEX9V5xisNh9FxM0RcUtEFO7dVee24ZFaNc4D/zMibgbu4+J4/WW/1Mf3z/Tv4el02nNRMDyENV/6O1xfmf22rKpa/pK2kBwTO1PSEeAbpH3E4UGi2tq6devYvXs3wMec2470B+ARYCC935pO3wa8KOnbJL8DLAL2NCPAvMv6sqNVFf+IWDfJ/KkOEmVNtmXLFgAkvRklxjh3btvH+Bf56dOn6erq4qmnnoKkpX+vpEeB94CHACIZ5fNlkks7ngf6ImKsWbFbdho2qqeZNcf4F3mhxx57bCwi7im1fNql83Sj47LW4oHdzMxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsjF38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsjF38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsjF38wsh3wZRzOzBqvk4uxZc8vfzCyHXPzNzHLIxd/MLIeqLv6S7pd0QNIhSf0l5q+SdEbSW+ntyfqEao00ODjI4sWLAZY7r51L0qikX6Y5HEqnzZC0U9LB9P66ZsdpjVdV8Zd0BfB94AFgKbBO0tISi/5bRHwqvf1dHeK0BhobG6Ovr48dO3YA7Md57XSfSXPYkz7vB3ZFxCJgV/rcOly1Lf8VwKGIeCci/gy8BKypf1iWpT179rBw4UIWLFgAEDivebMG2Jw+3gx8vnmhWFaqLf43AocLnh9JpxVbKWmfpB2Slk05OsvE0aNHmTt3buEk57VzBfAzScOS1qfT5kTEcYD0fnbTorPMVHucv0pMi6LnbwI3RcRZSb3Aq8Ciy1aU/OGtB5g3b16VYVg9RRSnMJlc9Nx57Qx3RcQxSbOBnZJ+XekLndvOUm3L/whQ2ETsAo4VLhARf4yIs+nj7cCVkmYWrygiNkZET0T0zJo1q8owrJ66uro4fPjwJZNwXjtSRBxL708Cr5B05Z6QdANAen+yzGud2w5SbfHfCyySNF/SVcBaYFvhApI+IUnp4xXpe7xfj2CtMW6//XYOHjzIu+++C8l/d85rB5I0XdLHxx8D9wEjJLl+JF3sEWBrcyK0LFXV7RMR5yU9AbwGXAE8HxH7JT2ezn8O+ALwZUnngf8A1kaZfgVrDdOmTWPDhg2sXr0aYBnw985rR5oDvJJ+h08DXoyIQUl7gZclPQq8BzzUxBgtI1WP7ZP+y7+9aNpzBY83ABtqD82y1NvbS29vL5JGIuJpcF47TUS8A9xaYvr7wD3ZR2TN5DN8zcxyyMXfzCyHPKSzmdWskiGLRwc+m0EkVim3/M3McsjF38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIdc/M3McsjF38wsh1z8zcxyyMXfzCyHXPzNzHLIxd/MLIc8sJuZdRwPNDc5t/zNzHLIxd/MLIfc7WNmVoNKuphakVv+ZmY55OJvZpZDLv5mZjnkPn8zy6W8Hw5adctf0v2SDkg6JKm/xHxJejad/7ak2+oTqjXS4OAgixcvBljuvObPZPu1dZ6qir+kK4DvAw8AS4F1kpYWLfYAsCi9rQd+WIc4rYHGxsbo6+tjx44dAPtxXnOlwv3aOky1Lf8VwKGIeCci/gy8BKwpWmYN8ONIvAFcK+mGOsRqDbJnzx4WLlzIggULAALnNW8q2a+tw1Tb538jcLjg+RHgjgqWuRE4XnV0lomjR48yd+7cwknOa75Usl9nol2PmW9H1RZ/lZgWU1gGSetJug8AzkkaqTKWVjQTON3sIKbgOuCaTZs2/Q5YnE5zXi9q17wWWjzBvKnk9qykAwWzJ91G+tZkITZN2dhbLeYS8dw01XVVW/yPAIVNxC7g2BSWISI2AhsBJA1FRE+VsbScdv0cklYC34yI1ZKGcF4v0QmfI81rOVXnttT623UbtXPstai2z38vsEjSfElXAWuBbUXLbAMeTo8OuRM4ExHuGmhtF/JK0gp0XvOlkv3aOkxVLf+IOC/pCeA14Arg+YjYL+nxdP5zwHagFzgE/An4Un1Dtnoryus84O+d1/wot183OSxrMEVc1rWXfRDS+vRfyrbWCZ+jnp+hE7YHdMbnaPRnaOdt1M6x16Ilir+ZmWXLY/uYmeVQpsW/E4aGqOAzrJJ0RtJb6e3JZsQ5EUnPSzpZ7jDMavPgvLaGeue1zDraNtedkOO6iohMbiQ/JP0WWABcBewDlhYt0wvsIDni5E7gF1nFV8fPsAr4SbNjneRz3A3cBoyUmV9xHpzX1rnVM6+dlutOyXE9b1m2/DthaIiOOA0+Il4HPphgkWry4Ly2iDrntZR2znVH5Liesiz+5YYHqHaZZqo0vpWS9knaIWlZNqHVVTV5cF7bR615aOdc5yXHFctyPP+6DQ3RRJXE9yZwU0ScldQLvEoyEmY7qSYPzmv7qDUP7ZzrvOS4Ylm2/Os2NEQTTRpfRPwxIs6mj7cDV0qamV2IdVFNHpzX9lFrHto513nJccWyLP6dMDTEpJ9B0ickKX28gmQbv595pLWpJg/Oa/uoNQ/tnOu85LhimXX7RAcMDVHhZ/gC8GVJ54H/ANZGeihBq5C0heTIhpmSjgDfAK6E6vPgvLaOeua1lHbOdafkuJ58hq+ZWQ75DF8zsxxy8TczyyEXfzOzHHLxNzPLIRd/M7MccvE3M8shF38zsxxy8Tczy6H/D54q96Jn1lfuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, (xx, yy) in enumerate(zip(X_valid[:5], y_valid[:5])):\n",
    "    ctx = featurizer.encrypt(xx)\n",
    "    dd = hec.decrypt(ctx)\n",
    "    \n",
    "    axs[i].hist(dd[:240])\n",
    "    \n",
    "    \n",
    "axs[-1].hist(ddl[:240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24259b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.13643712e-02,  3.16834505e-02,  5.68839646e-02, ...,\n",
       "       -3.46386337e-06, -2.30578526e-07, -1.99839230e-06])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1d06ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pred = Nmodel(torch.tensor(X_train[1].reshape(1,-1)).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "764ad28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  126.7263, -1325.0283, -6746.9990, 14051.2549, -7760.3872]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc44457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887150053714814"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b90f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pred = Nmodel(torch.tensor(X_train[:1]).float())\n",
    "#Nmodel(torch.tensor(X_valid[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe35ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -68.3079,  -4021.2930, -13188.7412,  24814.9121, -10345.2754]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d66646",
   "metadata": {},
   "source": [
    "여기서 만든 h_rf와 새로 만든 h_rf의 모양, 값 차이 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf0892",
   "metadata": {},
   "source": [
    "min = 0, \n",
    "max = 1인데.. 왜 -1보다 작아질까...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "912b3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1354.7771911621098,\n",
       " -657.0239105224605,\n",
       " -13200.904769897461,\n",
       " 19254.122360229492,\n",
       " -9825.276138305662]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25cbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe30cc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec179813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22183461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4410e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fase.core import commonAlgo\n",
    "class HETreeEvaluator:\n",
    "    \"\"\"Evaluator which will perform homomorphic computation\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 b0: np.ndarray, w1, b1, w2, b2,\n",
    "                 scheme,\n",
    "                 parms,\n",
    "                 activation_coeffs: List[float], \n",
    "                 #polynomial_evaluator: Callable,\n",
    "                 \n",
    "                 #relin_keys: seal.RelinKeys, galois_keys: seal.GaloisKeys, scale: float,\n",
    "                 do_reduction=True):\n",
    "        \"\"\"Initializes with the weights used during computation.\n",
    "\n",
    "        Args:\n",
    "            b0: bias of the comparison step\n",
    "\n",
    "        \"\"\"\n",
    "        self.sk = secretKey ######### \n",
    "        self.scheme = scheme\n",
    "        self.algo = he.SchemeAlgo(scheme)\n",
    "        self.commonAlgo = commonAlgo.CommonAlgorithms(scheme, \"HEAAN\")\n",
    "        # scheme should hold all keys\n",
    "        self.parms = parms\n",
    "        \n",
    "        self._activation_coeff = activation_coeffs\n",
    "        self._activation_poly_degree = len(activation_coeffs) -1\n",
    "        self.do_reduction = do_reduction\n",
    "\n",
    "        # 10-degree activation -> up to 5 multiplications \n",
    "        logq_w1 = self.parms.logq - 5 * self.parms.logp\n",
    "        logq_b1 = logq_w1 - self.parms.logp\n",
    "        logq_b2 = logq_b1 - 5*self.parms.logp\n",
    "\n",
    "        self.b0_ctx = self.encrypt(b0)\n",
    "        #self.b0 = b0\n",
    "        self.w1 = [self.to_double(w) for w in w1]\n",
    "        #self.b1 = b1\n",
    "        self.w2 = [self.to_double(w) for w in w2]\n",
    "        #self.b2 = [w for w in b2]\n",
    "        \n",
    "#         self.w1_ctx = []\n",
    "#         for w in w1:\n",
    "#             #print('w', w)\n",
    "#             temp = self.encrypt(w) \n",
    "#             scheme.modDownToAndEqual(temp, logq_w1)\n",
    "#             self.w1_ctx.append(temp)\n",
    "#         #self.w1_ctx = [self.encrypt(w, logq=logq_w1) for w in w1]\n",
    "            \n",
    "        self.b1_ctx = self.encrypt(b1, logq=logq_b1)\n",
    "#         self.w2_ctx = [self.encrypt(w, logq=logq_2) for w in w2]\n",
    "        self.b2_ctx = [self.encrypt(b, logq=logq_b2) for b in b2]\n",
    "\n",
    "        self.setup_summary()      \n",
    "    \n",
    "    def setup_summary(self):\n",
    "        print(\"CKKS paramters:\")\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"n = {self.parms.n}\")\n",
    "        print(f\"logp = {self.parms.logp}\")\n",
    "        print(f\"logq = {self.parms.logq}\")\n",
    "        print(f\"tanh activation polynomial coeffs = {self._activation_coeff}\")\n",
    "        print(f\"tanh activation polynomial degree = {self._activation_poly_degree}\")\n",
    "        \n",
    "        print(\"\\nNeural RF\")\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"\")\n",
    "    \n",
    "    def heaan_double(self, val):\n",
    "        mvec = np.zeros(self.parms.n)\n",
    "        mvec[:len(val)] = np.array(val)\n",
    "        return he.Double(mvec)\n",
    "\n",
    "    def decrypt_print(self, ctx, n=20):\n",
    "        res1 = self.decrypt(ctx)\n",
    "        print(\"_____________________\")\n",
    "        print(res1[:n])\n",
    "        print(res1.min(), res1.max())\n",
    "        print(\"---------------------\")\n",
    "\n",
    "    def decrypt(self, enc):\n",
    "        temp = self.scheme.decrypt(self.sk, enc)\n",
    "        arr = np.zeros(self.parms.n, dtype=np.complex128)\n",
    "        temp.__getarr__(arr)\n",
    "        return arr.real\n",
    "        \n",
    "    def encrypt_ravel(self, val, **kwargs):\n",
    "        \"\"\"encrypt a list\n",
    "        \"\"\"\n",
    "        return self.encrypt(np.array(val).ravel(), **kwargs)\n",
    "\n",
    "    def encrypt(self, val, n=None, logp=None, logq=None):\n",
    "        if n == None: n = self.parms.n\n",
    "        if logp == None: logp = self.parms.logp\n",
    "        if logq == None: logq = self.parms.logq\n",
    "            \n",
    "        ctxt = he.Ciphertext()\n",
    "        vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "        vv[:len(val)] = val\n",
    "        self.scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "        del vv\n",
    "        return ctxt\n",
    "    \n",
    "    def to_double(self, val):\n",
    "        n = self.parms.n\n",
    "        vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "        vv[:len(val)] = val\n",
    "        return he.Double(vv)\n",
    "        \n",
    "        \n",
    "    def activation(self, ctx):\n",
    "        output = he.Ciphertext()\n",
    "        #output = self.commonAlgo.function_poly(ctx, \n",
    "        #               he.Double(self._activation_coeff))\n",
    "        output = he.Ciphertext()\n",
    "        self.algo.function_poly(output, \n",
    "                    ctx, \n",
    "                    he.Double(self._activation_coeff), \n",
    "                    self.parms.logp, \n",
    "                    self._activation_poly_degree)\n",
    "        return output        \n",
    "        \n",
    "\n",
    "    def __call__(self, ctx):\n",
    "        # First we add the first bias to do the comparisons\n",
    "        ctx = self.compare(ctx)\n",
    "        print(\"After compare\")\n",
    "        self.decrypt_print(ctx)\n",
    "        ctx = self.match(ctx)\n",
    "        print(\"after match\")\n",
    "        self.decrypt_print(ctx)\n",
    "        outputs = self.decide(ctx)\n",
    "        if self.do_reduction:\n",
    "            outputs = self.reduce(outputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compare(self, ctx, debug=False):\n",
    "        \"\"\"Calculate first layer of the HNRF\n",
    "        \n",
    "        ctx = featurizer.encrypt(x)\n",
    "        \n",
    "        Assuming n, logp, logq are globally available\n",
    "        \n",
    "        \"\"\"\n",
    "        b0_ctx = self.b0_ctx\n",
    "        self.scheme.addAndEqual(ctx, b0_ctx)\n",
    "        # Activation\n",
    "        output = self.activation(ctx)\n",
    "            \n",
    "        del b0_ctx, ctx\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def _mat_mult(self, diagonals, ctx):\n",
    "        \"\"\"\n",
    "        Take plain vector \n",
    "        \"\"\"\n",
    "        scheme = self.scheme\n",
    "        n = self.parms.n\n",
    "        logp = self.parms.logp\n",
    "        #logq = self.parms.logq\n",
    "\n",
    "        ctx_copy = he.Ciphertext()\n",
    "        ctx_copy.copy(ctx)\n",
    "        \n",
    "        for i, diagonal in enumerate(diagonals):\n",
    "            #print(\"logq in mat_mult\", diagonal.logq, ctx_copy.logq)\n",
    "            #scheme.modDownToAndEqual(diagonal, ctx.logq)\n",
    "            if i > 0: scheme.leftRotateFastAndEqual(ctx_copy, 1) # r = 1\n",
    "\n",
    "            # Multiply with diagonal\n",
    "            dd = he.Ciphertext()\n",
    "            #print(\"diagonal\")\n",
    "            #self.decrypt_print(diagonal,10)\n",
    "            #print(\"ctx\")\n",
    "            #self.decrypt_print(ctx_copy,10)\n",
    "            #scheme.mult(dd, diagonal, ctx_copy)\n",
    "            \n",
    "            # Reduce the scale of diagonal\n",
    "            scheme.multByConstVec(dd, ctx_copy, diagonal, logp)\n",
    "            scheme.reScaleByAndEqual(dd, logp)\n",
    "            #print('dd')\n",
    "            #print(dd)\n",
    "            \n",
    "            \n",
    "            if i == 0:\n",
    "                mvec = np.zeros(n)\n",
    "                temp = he.Ciphertext()\n",
    "                scheme.encrypt(temp, he.Double(mvec), n, logp, ctx_copy.logq - logp)\n",
    "                ##scheme.modDownToAndEqual(temp, ctx_copy.logq)\n",
    "                #print(\"temp\",i)\n",
    "                #print(temp)\n",
    "                #self.decrypt_print(temp,10)\n",
    "            \n",
    "            # match scale \n",
    "            scheme.addAndEqual(temp, dd)\n",
    "\n",
    "            #print(\"temp\",i)\n",
    "            #self.decrypt_print(temp,10)\n",
    "            \n",
    "            del dd\n",
    "        del ctx_copy\n",
    "        return temp\n",
    "\n",
    "\n",
    "    def match(self, ctx):\n",
    "        \"\"\"Applies matching homomorphically.\n",
    "\n",
    "        First it does the matrix multiplication with diagonals, then activate it.\n",
    "        \"\"\"\n",
    "        output = self._mat_mult(self.w1, ctx)\n",
    "\n",
    "        #print(f\"MATCH:: 'output.logq', {output.logq} == {self.b1_ctx.logq}?\")\n",
    "        self.scheme.addAndEqual(output, self.b1_ctx)\n",
    "        \n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def decide(self, ctx):\n",
    "        \"\"\"Applies the decisions homomorphically.\n",
    "\n",
    "        For each class, multiply the ciphertext with the corresponding weight of that class and\n",
    "        add the bias afterwards.\n",
    "        \"\"\"\n",
    "        # ww와 bb도 미리 modDowntoAndEqual 가능 \n",
    "        outputs = []\n",
    "\n",
    "        for ww, bb in zip(self.w2, self.b2_ctx):\n",
    "            output = he.Ciphertext()\n",
    "            \n",
    "            # Multiply weights            \n",
    "            #self.scheme.mult(output, ww, ctx)\n",
    "            \n",
    "            scheme.multByConstVec(output, ctx, ww, ctx.logp)\n",
    "            #print(\"ctx\", ctx)\n",
    "            #print(\"bb\", bb)\n",
    "            self.scheme.reScaleByAndEqual(output, ctx.logp)\n",
    "            \n",
    "            # Add bias\n",
    "            self.scheme.addAndEqual(output, bb)\n",
    "            \n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    def _sum_reduce(self, ctx, logn, scheme):\n",
    "        \"\"\"\n",
    "        return sum of a Ciphertext (repeated nslot times)\n",
    "        \n",
    "        example\n",
    "        -------\n",
    "        sum_reduct([1,2,3,4,5])\n",
    "        >> [15,15,15,15,15]\n",
    "        \"\"\"\n",
    "        output = he.Ciphertext()\n",
    "        \n",
    "        for i in range(logn):\n",
    "            \n",
    "            if i == 0:\n",
    "                temp = he.Ciphertext(ctx.logp, ctx.logq, ctx.n)\n",
    "                #print(i, ctx, temp)\n",
    "                #print(\"reduce: ctx before rot\")\n",
    "                # self.decrypt_print(ctx,10)\n",
    "                \n",
    "                scheme.leftRotateFast(temp, ctx, 2**i)\n",
    "                #print(i, ctx, temp)\n",
    "                #print(\"reduce: before add\")\n",
    "                # self.decrypt_print(temp,10)\n",
    "                scheme.add(output, ctx, temp)\n",
    "                #print(\"reduce: after add\")\n",
    "                # self.decrypt_print(output,10)\n",
    "            else:\n",
    "                scheme.leftRotateFast(temp, output, 2**i)\n",
    "                #print(i, output, temp)\n",
    "                #print(\"reduce: before add\")\n",
    "                # self.decrypt_print(output,10)\n",
    "                # self.decrypt_print(temp,10)\n",
    "                scheme.addAndEqual(output, temp)\n",
    "                #print(\"reduce: after add\")\n",
    "                # self.decrypt_print(output,10)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def reduce(self, outputs):\n",
    "        logp = self.parms.logp\n",
    "        scheme = self.scheme\n",
    "\n",
    "        for i, output in enumerate(outputs):\n",
    "            # print(\"reduce before\",)\n",
    "            # self.decrypt_print(output,10)\n",
    "            #output = sum_reduce(output, self.parms.logn, self.scheme)\n",
    "            output = self._sum_reduce(output, self.parms.logn, self.scheme)\n",
    "\n",
    "            # print(\"reduce after\",)\n",
    "            # self.decrypt_print(output,10)\n",
    "\n",
    "            mask = np.zeros(self.parms.n)\n",
    "            mask[0] = 1\n",
    "            mask_hedb = he.ComplexDouble(mask)\n",
    "            if i == 0:\n",
    "                scores = he.Ciphertext()\n",
    "                scheme.multByConstVec(scores, output, mask_hedb, logp)\n",
    "                # print(\"reduce score\",i)\n",
    "                # self.decrypt_print(scores,10)\n",
    "                # print(\"before rescale\", scores)\n",
    "                scheme.reScaleByAndEqual(scores, logp)\n",
    "                # print(\"before rescale\", scores)\n",
    "            else:\n",
    "                temp = he.Ciphertext()\n",
    "                scheme.multByConstVec(temp, output, mask_hedb, logp)\n",
    "                # print(\"reduce score\",i)\n",
    "                # self.decrypt_print(scores,10)\n",
    "                # print(\"before rescale\", scores)\n",
    "                scheme.reScaleByAndEqual(temp, logp)\n",
    "                # print(\"after rescale\", scores)\n",
    "                scheme.rightRotateFastAndEqual(temp, i)\n",
    "                scheme.addAndEqual(scores, temp)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_model(cls, model,\n",
    "                   scheme,\n",
    "                   parms,\n",
    "                   activation_coeffs: List[float],\n",
    "                   do_reduction=False):\n",
    "        \"\"\"Creates an Homomorphic Tree Evaluator from a model, i.e a neural tree or\n",
    "        a neural random forest. \"\"\"\n",
    "        b0, w1, b1, w2, b2 = model.return_weights()\n",
    "\n",
    "        return cls(b0, w1, b1, w2, b2, scheme, parms, activation_coeffs, do_reduction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
