{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c94314f",
   "metadata": {},
   "source": [
    "FASE 대신 HEMUL 사용... 미완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40df7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from typing import List, Callable\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924abffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.tabular.all import *\n",
    "from fastai.metrics import accuracy\n",
    "from hnrf.misc import CrossEntropyLabelSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19858082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_print(ctx, n=20):\n",
    "    res1 = decrypt(secretKey, ctx)\n",
    "    print(res1[:n])\n",
    "    \n",
    "def decrypt(secretKey, enc):\n",
    "    featurized = scheme.decrypt(secretKey, enc)\n",
    "    arr = np.zeros(n, dtype=np.complex128)\n",
    "    featurized.__getarr__(arr)\n",
    "    return arr.real\n",
    "\n",
    "def encrypt(val):\n",
    "    ctxt = he.Ciphertext()#logp, logq, n)\n",
    "    vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "    vv[:len(val)] = val\n",
    "    scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "    del vv\n",
    "    return ctxt\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class TabularDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        'Initialization'\n",
    "        self.X, self.y = X,y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.tensor(self.X[index]).float()\n",
    "        y = torch.tensor(self.y[index])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "class Param():\n",
    "    def __init__(self, n=None, logn=None, logp=None, logq=None, logQboot=None):\n",
    "        self.n = n\n",
    "        self.logn = logn\n",
    "        self.logp = logp\n",
    "        self.logq = logq \n",
    "        self.logQboot = logQboot\n",
    "        if self.logn == None:\n",
    "            self.logn = int(np.log2(n))\n",
    "            \n",
    "CAM_LIST= {1: \"e\",\n",
    "           2: \"e\",\n",
    "           3: \"a\",\n",
    "           4: \"e\",\n",
    "           5: \"e\",\n",
    "           6: \"e\",\n",
    "           7: \"e\",\n",
    "           8: \"a\",\n",
    "           9: \"a\",\n",
    "           10:\"e\",\n",
    "           11:\"e\",\n",
    "           12:\"e\",\n",
    "           13:\"a\",\n",
    "           14:\"e\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29953609",
   "metadata": {},
   "source": [
    "# Train a RF model  -- smaller example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c98f5",
   "metadata": {},
   "source": [
    "matcher를 풀고 train하면 성능이 쉽게 올라가지만 중간에 계산값이 +/- 1을 넘어갈 가능성이 높아질 것 같음.  \n",
    "근데 matcher 안 풀고는 좀처럼 성능이 올라가지 않음... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece03e9",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fb1640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "min max of input dataset\n",
      "0.0 1.0000000000000002\n",
      "0.0 1.0000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/bbs/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.0.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/hoseung/anaconda3/envs/bbs/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.0.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./\"\n",
    "\n",
    "action = 14\n",
    "cam = CAM_LIST[action]\n",
    "\n",
    "fn_model_out = f\"trained_model_{action}_{cam}.pickle\"\n",
    "fn_data_out = f\"BBS_dataset_{action}_{cam}.pickle\"\n",
    "\n",
    "fn_model = model_dir + fn_model_out\n",
    "fn_dat = model_dir + fn_data_out\n",
    "\n",
    "rf_model = pickle.load(open(fn_model, \"rb\"))\n",
    "\n",
    "print(\"model's depth:\", rf_model.max_depth)\n",
    "print(\"model's tree count:\", rf_model.n_estimators)\n",
    "\n",
    "\n",
    "#####\n",
    "dataset = pickle.load(open(fn_dat, \"rb\"))\n",
    "\n",
    "X_train = dataset[\"train_x\"]\n",
    "y_train = dataset[\"train_y\"]\n",
    "X_valid = dataset[\"valid_x\"]\n",
    "y_valid = dataset[\"valid_y\"]\n",
    "\n",
    "print(\"min max of input dataset\")\n",
    "print(X_train.min(), X_train.max())\n",
    "print(X_valid.min(), X_valid.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c27ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnrf\n",
    "\n",
    "from hnrf.nrf import NeuralTreeMaker, NeuralRF\n",
    "from sklearn.tree import BaseDecisionTree\n",
    "\n",
    "dilatation_factor = 15\n",
    "polynomial_degree = 31\n",
    "\n",
    "estimators = rf_model.estimators_\n",
    "\n",
    "my_tm_tanh = NeuralTreeMaker(torch.tanh, \n",
    "                            use_polynomial=True,\n",
    "                            dilatation_factor=dilatation_factor, \n",
    "                            polynomial_degree=polynomial_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806b824",
   "metadata": {},
   "source": [
    "A Neural Decision Tree consists of: \n",
    "1. activation function\n",
    "2. Coeffs\n",
    "3. weight loader \n",
    "4. forward method \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e13f383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.9737470167064439\n",
      "Accuracy of tanh : 0.5091487669053302\n",
      "Match between tanh and original : 0.522673031026253\n"
     ]
    }
   ],
   "source": [
    "Nmodel =NeuralRF(estimators, my_tm_tanh)\n",
    "\n",
    "# NRF 성능 테스트\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_train).float()).argmax(dim=1).numpy()\n",
    "\n",
    "pred = rf_model.predict(X_train)\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "print(f\"Accuracy of tanh : {(neural_pred == y_train).mean()}\")\n",
    "print(f\"Match between tanh and original : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2d47e",
   "metadata": {},
   "source": [
    "## Refine NRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning\n",
    "save = False\n",
    "Nmodel.freeze_layer(\"comparator\")\n",
    "Nmodel.freeze_layer(\"matcher\")\n",
    "\n",
    "for p in Nmodel.parameters():\n",
    "    print(p.shape, p.requires_grad)\n",
    "\n",
    "bs = 128\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "valid_ds = TabularDataset(X_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)\n",
    "\n",
    "learn = Learner(dls, Nmodel, loss_func=CrossEntropyLabelSmoothing())\n",
    "\n",
    "learn.lr_find()\n",
    "#learn.recorder.plot()\n",
    "learn.fit_one_cycle(30, 0.3)\n",
    "\n",
    "## Fine-tuned NRF model\n",
    "pred = rf_model.predict(X_valid)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_valid).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_valid).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_valid).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8585731d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.798364</td>\n",
       "      <td>0.834967</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.797405</td>\n",
       "      <td>0.838596</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.800227</td>\n",
       "      <td>0.836187</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.802914</td>\n",
       "      <td>0.847937</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.804175</td>\n",
       "      <td>0.847038</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.806018</td>\n",
       "      <td>0.868449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.813086</td>\n",
       "      <td>0.848174</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.812943</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.810615</td>\n",
       "      <td>0.856387</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>0.857385</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.805058</td>\n",
       "      <td>0.829844</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.805939</td>\n",
       "      <td>0.900954</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.806123</td>\n",
       "      <td>0.826881</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.803737</td>\n",
       "      <td>0.841210</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.800879</td>\n",
       "      <td>0.824142</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.796441</td>\n",
       "      <td>0.826452</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>0.839084</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.791893</td>\n",
       "      <td>0.832386</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.790799</td>\n",
       "      <td>0.830823</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.788118</td>\n",
       "      <td>0.822588</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.785578</td>\n",
       "      <td>0.820612</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.785217</td>\n",
       "      <td>0.823849</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.783776</td>\n",
       "      <td>0.820395</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.782872</td>\n",
       "      <td>0.822639</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.781798</td>\n",
       "      <td>0.821609</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.781735</td>\n",
       "      <td>0.818908</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.781118</td>\n",
       "      <td>0.818217</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.780485</td>\n",
       "      <td>0.818140</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.778973</td>\n",
       "      <td>0.818089</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.778290</td>\n",
       "      <td>0.818097</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.9345380156836004\n",
      "Accuracy : 0.8564609614728946\n",
      "Same output : 0.8503239004432321\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(30, 0.04)\n",
    "\n",
    "## Fine-tuned NRF model\n",
    "pred = rf_model.predict(X_valid)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_valid).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_valid).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_valid).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc1ecb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if save:\n",
    "    pickle.dump(Nmodel, open(f\"Nmodel_{action}_{cam}.pickle\", \"wb\"))\n",
    "if else:\n",
    "    Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b07ef",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2194cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU version HEAAN\n"
     ]
    }
   ],
   "source": [
    "from hnrf.hnrf import HEDT\n",
    "homomorphic_trees = [HEDT(w0, b0, w1, b1, w2, b2)\n",
    "                    for (w0, b0, w1, b1, w2, b2) in zip(*Nmodel.return_weights())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d56e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = homomorphic_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5c6f53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([215,  16,  99, 209, 171, 212, 218,  60,  19,  44, 188, 181, 218,\n",
       "        69,  20, 111, 163, 230,  18,  40, 195, 211, 109, 163, 240,  49,\n",
       "        23, 233, 151, 161,  54,  96, 120, 132,  42,   5,  29,   0, 169,\n",
       "        68, 123,  13, 239,  51,  26, 131, 163, 125,  56,  31, 106,  92,\n",
       "       182, 228, 110,  20, 152,  87, 131, 226, 200,  89, 192,  91, 174,\n",
       "       120,  77, 191, 181, 171, 102, 101, 191, 141, 138,  14, 230,  52,\n",
       "       136, 232,  53,  13, 101, 195,  82,  -1,  -1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6877f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.w1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9cd59",
   "metadata": {},
   "source": [
    "Input vector = 241 = 30*8 + 1 (N_tot_frame 비슷한 거였음)\n",
    "\n",
    "weight = 87 < 128. 질문들. \n",
    "\n",
    "따라서, \n",
    "\n",
    "241 * 87(<128) * 20 만큼의 곱하기 수행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ef0139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5866, 241])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(X_valid).float().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b1a1125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([241, 87, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.comparator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02b382e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Nmodel.comparator[:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75619841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Nmodel.comparator[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae392788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1. 0. 1. 1. 2. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 2. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0.\n",
      " 0. 1. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 1. 0. 0. 2.\n",
      " 1. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 2. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 2. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 2. 2. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 0. 2. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 2. 0. 0. 0. 1. 0.\n",
      " 2.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 2. 2. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 2. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 2. 2. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 2. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 3.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 2. 1. 0. 0. 0. 0. 1. 0. 0. 2. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 2. 0. 0. 0. 0. 1. 0. 1. 2. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 2. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 2. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 2. 0. 0. 0. 2.\n",
      " 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 2. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.\n",
      " 3.]\n",
      "[0. 2. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 2. 0. 1. 0. 0. 1. 2. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 2.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 3. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 3. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 2.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 2. 0. 0. 0. 0. 1. 0. 2. 0. 0. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 2. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 2. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 3. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 4. 2. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1.]\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 2. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 3. 0. 2. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 2. 3. 2. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 2. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n",
      " 2.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 2. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 0. 2. 1. 1. 1. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 2. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 2. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 0. 0. 0. 0. 0.\n",
      " 2.]\n",
      "[0. 0. 3. 0. 0. 2. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 2. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 3. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 2. 2. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 4.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 3. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 2. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 3. 1. 0. 1. 0.\n",
      " 1. 1. 2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 5.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 2. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 2. 0. 0. 0. 0. 2. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 2. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 3. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 2. 0. 0.\n",
      " 2.]\n",
      "[1. 1. 2. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 2. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 2. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 2. 1. 0. 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2.\n",
      " 0. 3. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 3.]\n",
      "[0. 2. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 2. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 2.]\n",
      "[0. 0. 0. 2. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 2. 0. 0. 2. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 1. 0. 1. 0. 2. 1. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 3.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 3. 0.\n",
      " 0. 0. 2. 1. 1. 0. 0. 0. 0. 1. 0. 1. 2. 1. 1. 0. 1. 0. 0. 0. 0. 2. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 2. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 2. 1. 0. 0. 0. 1. 1. 2. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 2. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 3.]\n",
      "[2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 3. 0. 1. 0. 0. 0. 2. 0. 0. 1. 1. 0. 3. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 2. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 1. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1.\n",
      " 2.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0.\n",
      " 0. 0. 0. 1. 2. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 3.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 2. 0. 2. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 2. 0. 1. 0. 0. 1. 0. 0. 0. 2. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 2. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 2. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 2. 0. 0. 0. 0. 1. 2. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 3.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 1. 1. 2. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 2. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 2. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 2. 0. 1. 1. 2. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 2. 0. 0. 1. 0. 1.\n",
      " 4.]\n"
     ]
    }
   ],
   "source": [
    "# 많아야 1 변수가 2번 질문 받음. \n",
    "# 241 * 88 이지만 사실 241 * 1에 가까운 계산량.\n",
    "for i in range(Nmodel.comparator.shape[-1]):\n",
    "    nnc = Nmodel.comparator[...,i].detach().numpy()\n",
    "    print(np.sum(nnc, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49832d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 87, 20])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Nmodel.matcher.shape)\n",
    "plt.imshow(Nmodel.matcher[:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9b6e623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07484326018808778"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Nmodel.matcher[:,:,0].detach().numpy() != 0) / np.prod(Nmodel.matcher.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1678549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 88, 20])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Nmodel.head.shape)\n",
    "plt.imshow(Nmodel.head[:,:,0].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13d931ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([87, 20])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.comparator_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2303cc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 87, 20])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.matcher.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1d51c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 88, 20])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389bd1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NeuralRF.decide of NeuralRF()>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2551b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum(\"kj,jil->kil\", x, Nmodel.comparator) + Nmodel.comparator_bias.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9105894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagonal(arr):\n",
    "    nr, nc = arr.shape\n",
    "    new_mat = np.zeros((nr, nc), dtype=arr.dtype)\n",
    "    \n",
    "    for j in range(nr):\n",
    "        for i in range(nc):\n",
    "            new_mat[j, i] = arr[i%nr, (i+j)%nc]\n",
    "            #new_mat[j, i] = arr[i%nr, (i+j)%nc]\n",
    "    return new_mat\n",
    "\n",
    "def diagonal_matmult(WW, VV):\n",
    "    HS_result = None\n",
    "    nr, nc = WW.shape\n",
    "    for i in range(nr):\n",
    "        if HS_result is None:\n",
    "            HS_result = WW[i] * VV\n",
    "        else:\n",
    "            HS_result += WW[i] * np.roll(VV,-i)\n",
    "    return HS_result\n",
    "\n",
    "def pack(arr, n=32768):\n",
    "    newarr = np.zeros(n, dtype=int)\n",
    "    newarr[:len(arr)] = arr\n",
    "    return newarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a759c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = 8\n",
    "no = 4\n",
    "\n",
    "W0 = np.arange(ni*no).reshape(no,ni)\n",
    "W1 = [pack(w) for w in W0]\n",
    "V0 = np.random.randint(1,10,ni)\n",
    "V1 = pack(V0)\n",
    "\n",
    "W5 = get_diagonal(W0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8b374e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29, 30, 31]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15ab470a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 8, 3, 4, 5, 6, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b90c3d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cffbbb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 241 into shape (88)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23585/731352025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiagonal_matmult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 241 into shape (88)"
     ]
    }
   ],
   "source": [
    "hs = diagonal_matmult(W5, V0)\n",
    "print(np.sum(hs.reshape(-1, no), axis=0))\n",
    "\n",
    "print(np.matmul(W0, V0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e676218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "797ae0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = homomorphic_trees[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53056e4f",
   "metadata": {},
   "source": [
    "HEDT가 multiplication 준비하는 단계. \n",
    "여기에 새 mat_mult위한 준비 필요. \n",
    "\n",
    "matrix 곱하기 모양은 nrf.py에서 확인. \n",
    "compare, match, decide 모두 torch.einsum으로 돌아감. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0713512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56347209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hnrf.hnrf.HEDT at 0x7f804a447790>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58a4e68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b1a34b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa50ba",
   "metadata": {},
   "source": [
    "# FHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0930588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "generic_type: type \"ZZ\" is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from hnrf.hnrf import HNRF\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhnrf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhetree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HNRF\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m h_rf \u001b[38;5;241m=\u001b[39m HNRF(Nmodel)\n",
      "File \u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nrf\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fhe_utils\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m heaan_nrf\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n",
      "File \u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/fhe_utils.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheaan\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhe\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#n = parms.n\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#logp = parms.logp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#logq = parms.logq\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecrypt_print\u001b[39m(ctx, secretKey, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, ):\n",
      "File \u001b[0;32m~/Work/fhe-ai-sw-etri/fase/core/heaan.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#from fase.core.heaan import he\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheaan_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[0;32m----> 6\u001b[0m he \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mHEAANContext\u001b[39;00m():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     10\u001b[0m                 scale_bit: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 logp: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 FN_ROT\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRotKey.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m                 FN_CONJ\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConjKey.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Work/fhe-ai-sw-etri/fase/heaan_loader.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing CUDA version HEAAN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHEAAN\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhe\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing CPU version HEAAN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m he\n",
      "\u001b[0;31mImportError\u001b[0m: generic_type: type \"ZZ\" is already registered!"
     ]
    }
   ],
   "source": [
    "#from hnrf.hnrf import HNRF\n",
    "from fase.hnrf.hetree import HNRF\n",
    "#Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))\n",
    "h_rf = HNRF(Nmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb59ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logq = 540\n",
    "logp = 30\n",
    "logn = 14 # 질문 * Ntree\n",
    "n = 1*2**logn\n",
    "slots = n\n",
    "\n",
    "parms = Param(n=n, logp=logp, logq=logq)\n",
    "\n",
    "do_reduction=False\n",
    "\n",
    "ring = he.Ring()\n",
    "secretKey = he.SecretKey(ring)\n",
    "scheme = he.Scheme(secretKey, ring, False)\n",
    "\n",
    "algo = he.SchemeAlgo(scheme)\n",
    "\n",
    "# reduction때는 right rotation N_class개 필요. \n",
    "if do_reduction:\n",
    "    Nclass = Nmodel.head.shape[0]\n",
    "    scheme.addLeftRotKeys(secretKey)\n",
    "    for i in range(Nclass):\n",
    "        scheme.addRightRotKey(secretKey, i+1) # \n",
    "else:\n",
    "    # reduction 안 하면 하나짜리 rotation만 여러번 반복.\n",
    "    scheme.addLeftRotKey(secretKey, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ab51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3866f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fase.core import commonAlgo\n",
    "class HETreeEvaluator:\n",
    "    \"\"\"Evaluator which will perform homomorphic computation\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 b0: np.ndarray, w1, b1, w2, b2,\n",
    "                 scheme,\n",
    "                 parms,\n",
    "                 activation_coeffs: List[float], \n",
    "                 #polynomial_evaluator: Callable,\n",
    "                 \n",
    "                 #relin_keys: seal.RelinKeys, galois_keys: seal.GaloisKeys, scale: float,\n",
    "                 do_reduction=True):\n",
    "        \"\"\"Initializes with the weights used during computation.\n",
    "\n",
    "        Args:\n",
    "            b0: bias of the comparison step\n",
    "\n",
    "        \"\"\"\n",
    "        self.sk = secretKey ######### \n",
    "        self.scheme = scheme\n",
    "        self.algo = he.SchemeAlgo(scheme)\n",
    "        self.commonAlgo = commonAlgo.CommonAlgorithms(scheme, \"HEAAN\")\n",
    "        # scheme should hold all keys\n",
    "        self.parms = parms\n",
    "        \n",
    "        self._activation_coeff = activation_coeffs\n",
    "        self._activation_poly_degree = len(activation_coeffs) -1\n",
    "        self.do_reduction = do_reduction\n",
    "\n",
    "        # 10-degree activation -> up to 5 multiplications \n",
    "        logq_w1 = self.parms.logq - 5 * self.parms.logp\n",
    "        logq_b1 = logq_w1 - self.parms.logp\n",
    "        logq_b2 = logq_b1 - 5*self.parms.logp\n",
    "\n",
    "        self.b0_ctx = self.encrypt(b0)\n",
    "        self.w1 = [self.to_double(w) for w in w1]\n",
    "        self.w2 = [self.to_double(w) for w in w2]\n",
    "        \n",
    "        self.b1_ctx = self.encrypt(b1, logq=logq_b1)\n",
    "        self.b2_ctx = [self.encrypt(b, logq=logq_b2) for b in b2]\n",
    "\n",
    "        self.setup_summary()      \n",
    "    \n",
    "    def setup_summary(self):\n",
    "        print(\"CKKS paramters:\")\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"n = {self.parms.n}\")\n",
    "        print(f\"logp = {self.parms.logp}\")\n",
    "        print(f\"logq = {self.parms.logq}\")\n",
    "        print(f\"tanh activation polynomial coeffs = {self._activation_coeff}\")\n",
    "        print(f\"tanh activation polynomial degree = {self._activation_poly_degree}\")\n",
    "        \n",
    "        print(\"\\nNeural RF\")\n",
    "        print(\"---------------------------\")\n",
    "        print(f\"\")\n",
    "    \n",
    "    def heaan_double(self, val):\n",
    "        mvec = np.zeros(self.parms.n)\n",
    "        mvec[:len(val)] = np.array(val)\n",
    "        return he.Double(mvec)\n",
    "\n",
    "    def decrypt_print(self, ctx, n=20):\n",
    "        res1 = self.decrypt(ctx)\n",
    "        print(\"_____________________\")\n",
    "        print(res1[:n])\n",
    "        print(res1.min(), res1.max())\n",
    "        print(\"---------------------\")\n",
    "\n",
    "    def decrypt(self, enc):\n",
    "        temp = self.scheme.decrypt(self.sk, enc)\n",
    "        arr = np.zeros(self.parms.n, dtype=np.complex128)\n",
    "        temp.__getarr__(arr)\n",
    "        return arr.real\n",
    "        \n",
    "    def encrypt_ravel(self, val, **kwargs):\n",
    "        \"\"\"encrypt a list\n",
    "        \"\"\"\n",
    "        return self.encrypt(np.array(val).ravel(), **kwargs)\n",
    "\n",
    "    def encrypt(self, val, n=None, logp=None, logq=None):\n",
    "        if n == None: n = self.parms.n\n",
    "        if logp == None: logp = self.parms.logp\n",
    "        if logq == None: logq = self.parms.logq\n",
    "            \n",
    "        ctxt = he.Ciphertext()\n",
    "        vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "        vv[:len(val)] = val\n",
    "        self.scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "        del vv\n",
    "        return ctxt\n",
    "    \n",
    "    def to_double(self, val):\n",
    "        n = self.parms.n\n",
    "        vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "        vv[:len(val)] = val\n",
    "        return he.Double(vv)\n",
    "        \n",
    "        \n",
    "    def activation(self, ctx):\n",
    "        output = he.Ciphertext()\n",
    "        output = he.Ciphertext()\n",
    "        self.algo.function_poly(output, \n",
    "                    ctx, \n",
    "                    he.Double(self._activation_coeff), \n",
    "                    self.parms.logp, \n",
    "                    self._activation_poly_degree)\n",
    "        return output        \n",
    "        \n",
    "\n",
    "    def __call__(self, ctx):\n",
    "        # First we add the first bias to do the comparisons\n",
    "        ctx = self.compare(ctx)\n",
    "        print(\"After compare\")\n",
    "        self.decrypt_print(ctx)\n",
    "        ctx = self.match(ctx)\n",
    "        print(\"after match\")\n",
    "        self.decrypt_print(ctx)\n",
    "        outputs = self.decide(ctx)\n",
    "        if self.do_reduction:\n",
    "            outputs = self.reduce(outputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compare(self, ctx, debug=False):\n",
    "        \"\"\"Calculate first layer of the HNRF\n",
    "        \n",
    "        ctx = featurizer.encrypt(x)\n",
    "        \n",
    "        Assuming n, logp, logq are globally available\n",
    "        \n",
    "        \"\"\"\n",
    "        b0_ctx = self.b0_ctx\n",
    "        self.scheme.addAndEqual(ctx, b0_ctx)\n",
    "        # Activation\n",
    "        output = self.activation(ctx)\n",
    "            \n",
    "        del b0_ctx, ctx\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def _mat_mult(self, diagonals, ctx):\n",
    "        \"\"\"\n",
    "        Take plain vector \n",
    "        \"\"\"\n",
    "        scheme = self.scheme\n",
    "        n = self.parms.n\n",
    "        logp = self.parms.logp\n",
    "        #logq = self.parms.logq\n",
    "\n",
    "        ctx_copy = he.Ciphertext()\n",
    "        ctx_copy.copy(ctx)\n",
    "        \n",
    "        for i, diagonal in enumerate(diagonals):\n",
    "            if i > 0: scheme.leftRotateFastAndEqual(ctx_copy, 1) # r = 1\n",
    "\n",
    "            # Multiply with diagonal\n",
    "            dd = he.Ciphertext()\n",
    "            \n",
    "            # Reduce the scale of diagonal\n",
    "            scheme.multByConstVec(dd, ctx_copy, diagonal, logp)\n",
    "            scheme.reScaleByAndEqual(dd, logp)\n",
    "            \n",
    "            if i == 0:\n",
    "                mvec = np.zeros(n)\n",
    "                temp = he.Ciphertext()\n",
    "                scheme.encrypt(temp, he.Double(mvec), n, logp, ctx_copy.logq - logp)\n",
    "            \n",
    "            # match scale \n",
    "            scheme.addAndEqual(temp, dd)\n",
    "\n",
    "            #print(\"temp\",i)\n",
    "            #self.decrypt_print(temp,10)\n",
    "            \n",
    "            del dd\n",
    "        del ctx_copy\n",
    "        return temp\n",
    "\n",
    "\n",
    "    def match(self, ctx):\n",
    "        \"\"\"Applies matching homomorphically.\n",
    "\n",
    "        First it does the matrix multiplication with diagonals, then activate it.\n",
    "        \"\"\"\n",
    "        output = self._mat_mult(self.w1, ctx)\n",
    "\n",
    "        #print(f\"MATCH:: 'output.logq', {output.logq} == {self.b1_ctx.logq}?\")\n",
    "        self.scheme.addAndEqual(output, self.b1_ctx)\n",
    "        \n",
    "        output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "    def decide(self, ctx):\n",
    "        \"\"\"Applies the decisions homomorphically.\n",
    "\n",
    "        For each class, multiply the ciphertext with the corresponding weight of that class and\n",
    "        add the bias afterwards.\n",
    "        \"\"\"\n",
    "        # ww와 bb도 미리 modDowntoAndEqual 가능 \n",
    "        outputs = []\n",
    "\n",
    "        for ww, bb in zip(self.w2, self.b2_ctx):\n",
    "            output = he.Ciphertext()\n",
    "            \n",
    "            # Multiply weights            \n",
    "            scheme.multByConstVec(output, ctx, ww, ctx.logp)\n",
    "            #print(\"ctx\", ctx)\n",
    "            #print(\"bb\", bb)\n",
    "            self.scheme.reScaleByAndEqual(output, ctx.logp)\n",
    "            \n",
    "            # Add bias\n",
    "            self.scheme.addAndEqual(output, bb)\n",
    "            \n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    def _sum_reduce(self, ctx, logn, scheme):\n",
    "        \"\"\"\n",
    "        return sum of a Ciphertext (repeated nslot times)\n",
    "        \n",
    "        example\n",
    "        -------\n",
    "        sum_reduct([1,2,3,4,5])\n",
    "        >> [15,15,15,15,15]\n",
    "        \"\"\"\n",
    "        output = he.Ciphertext()\n",
    "        \n",
    "        for i in range(logn):\n",
    "            \n",
    "            if i == 0:\n",
    "                temp = he.Ciphertext(ctx.logp, ctx.logq, ctx.n)\n",
    "                \n",
    "                scheme.leftRotateFast(temp, ctx, 2**i)\n",
    "                scheme.add(output, ctx, temp)\n",
    "            else:\n",
    "                scheme.leftRotateFast(temp, output, 2**i)\n",
    "                scheme.addAndEqual(output, temp)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def reduce(self, outputs):\n",
    "        logp = self.parms.logp\n",
    "        scheme = self.scheme\n",
    "\n",
    "        for i, output in enumerate(outputs):\n",
    "            output = self._sum_reduce(output, self.parms.logn, self.scheme)\n",
    "\n",
    "            mask = np.zeros(self.parms.n)\n",
    "            mask[0] = 1\n",
    "            mask_hedb = he.ComplexDouble(mask)\n",
    "            if i == 0:\n",
    "                scores = he.Ciphertext()\n",
    "                scheme.multByConstVec(scores, output, mask_hedb, logp)\n",
    "                scheme.reScaleByAndEqual(scores, logp)\n",
    "            else:\n",
    "                temp = he.Ciphertext()\n",
    "                scheme.multByConstVec(temp, output, mask_hedb, logp)\n",
    "                scheme.reScaleByAndEqual(temp, logp)\n",
    "                scheme.rightRotateFastAndEqual(temp, i)\n",
    "                scheme.addAndEqual(scores, temp)\n",
    "\n",
    "        return scores\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_model(cls, model,\n",
    "                   scheme,\n",
    "                   parms,\n",
    "                   activation_coeffs: List[float],\n",
    "                   do_reduction=False):\n",
    "        \"\"\"Creates an Homomorphic Tree Evaluator from a model, i.e a neural tree or\n",
    "        a neural random forest. \"\"\"\n",
    "        b0, w1, b1, w2, b2 = model.return_weights()\n",
    "\n",
    "        return cls(b0, w1, b1, w2, b2, scheme, parms, activation_coeffs, do_reduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935ad25",
   "metadata": {},
   "source": [
    "## To do\n",
    "1. mat_mult만 따로 떼서 새 버전과 비교\n",
    "2. 여러개의 DT가 어떻게 하나의 weight로 합쳐지는지 이해\n",
    "3. 하나의 DT를 하나의 W로 두고 마지막에 합치는 방법 고려\n",
    "4. 최대 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9aa19c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HETreeEvaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23585/674744017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nrf_evaluator = HETreeEvaluator.from_model(h_rf,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                             \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             \u001b[0mparms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                             \u001b[0mmy_tm_tanh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                             \u001b[0mdo_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HETreeEvaluator' is not defined"
     ]
    }
   ],
   "source": [
    "nrf_evaluator = HETreeEvaluator.from_model(h_rf,\n",
    "                                            scheme,\n",
    "                                            parms,\n",
    "                                            my_tm_tanh.coeffs,\n",
    "                                            do_reduction = do_reduction\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c3bdd",
   "metadata": {},
   "source": [
    "이거를 빨리... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00e8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2dd048c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'heaan_nrf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23585/3693171766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeaturizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaan_nrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHETreeFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_comparator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'heaan_nrf' is not defined"
     ]
    }
   ],
   "source": [
    "featurizer = heaan_nrf.HETreeFeaturizer(h_rf.return_comparator(), scheme, parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "525aef21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After compare\n",
      "_____________________\n",
      "[-3553.537785   633.312096   986.104281  -787.331721   753.215784    17.463915  2229.890549  -523.92082    928.679984\n",
      "   485.509195 -1378.30313     90.998323    77.088115   -61.983928   -28.754441  2653.945035  -150.272121   963.285134\n",
      "  -841.769644   127.686831]\n",
      "-5333.147424207689 5691.436050251888\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[ 7.852005e+37 -1.294581e+38  2.877582e+36 -3.370628e+37 -4.385838e+37 -2.508176e+37 -7.089489e+37  3.428295e+37\n",
      " -4.342916e+36 -6.037652e+37 -5.534335e+36  6.614096e+37 -3.197613e+37  1.451282e+37  2.682505e+37  1.911827e+37\n",
      "  5.009485e+36  9.673895e+36 -6.125014e+37  3.132460e+37]\n",
      "-1.8520879702038686e+38 1.9058639152915016e+38\n",
      "---------------------\n",
      "Prediction: 4 == 1?\n",
      "[-3.71161233210469e+30, 9.307488528757506e+29, -3.2933943702326227e+30, -9.905789000637382e+30, 6.252425452385588e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "320.9232385158539 seconds\n",
      "After compare\n",
      "_____________________\n",
      "[ -235.635208  -943.15398  -1301.814741  -347.100185  -502.662327  -255.86125   2532.937989  1227.177451  -149.029126\n",
      "  -645.665919  1230.19121    491.11025   2050.2035   -1580.161547  1016.711548  1435.417943  -905.452558   105.495409\n",
      "   128.961018   103.559585]\n",
      "-5093.908634793589 6203.6942013074395\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[-4.055771e+37  2.535365e+37  1.583852e+37 -3.028829e+37  7.643601e+36 -2.762211e+37 -2.660290e+37  1.645228e+37\n",
      "  3.564637e+37  6.832426e+37  8.176236e+36 -2.653088e+37  1.251013e+37 -6.637836e+37 -3.249653e+37 -7.071146e+37\n",
      " -1.668096e+37 -9.011005e+37 -3.903279e+37 -3.546487e+37]\n",
      "-1.973649056579077e+38 1.9488920201152825e+38\n",
      "---------------------\n",
      "Prediction: 2 == 3?\n",
      "[-7.802566055601398e+30, -1.2610083974848653e+30, 9.672224523122543e+30, -8.904715054423057e+30, -2.67620991750405e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "320.7123508453369 seconds\n",
      "After compare\n",
      "_____________________\n",
      "[-2.291012e+03  1.555178e+00 -2.365029e+02 -2.945746e+02 -8.717615e+02 -1.998846e+02  9.068630e+02  1.031169e+03\n",
      " -8.930495e+01  5.945445e+02  1.325331e+03  8.752705e+02 -1.898053e+02 -4.888237e+02 -1.418128e+03  4.543078e+02\n",
      " -1.478649e+03  1.188979e+02  1.117645e+03  1.615566e+03]\n",
      "-4658.492464438119 5093.282041732371\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[-4.776948e+37  1.054919e+37 -2.219667e+37  2.016499e+37  3.214528e+37  8.093641e+37 -1.882962e+37  3.504283e+37\n",
      " -1.113077e+38  2.340546e+37  1.397401e+37  8.368155e+37 -1.823446e+37  4.566435e+37  1.489273e+37  3.228851e+37\n",
      " -1.018208e+37 -1.211039e+37  3.534537e+37  1.735513e+36]\n",
      "-2.055498606769217e+38 1.9533358152941596e+38\n",
      "---------------------\n",
      "Prediction: 1 == 3?\n",
      "[-3.8615763668015525e+30, 1.6360122624028613e+30, -1.3623950147429774e+30, -5.231040938990557e+30, -5.242254234359813e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "319.717000246048 seconds\n",
      "After compare\n",
      "_____________________\n",
      "[ 1211.115754    76.620439   150.900549   484.705791  -233.436832  -126.717039 -1122.413874 -1415.565451 -1028.147394\n",
      "   492.720089  -438.530197   288.569848 -1641.897741  -314.865551  -382.59461    528.816216   217.738591  -272.827607\n",
      "  -786.363107  -494.700473]\n",
      "-6162.405257997043 6042.010955123566\n",
      "---------------------\n",
      "after match\n",
      "_____________________\n",
      "[-5.137252e+37 -2.193313e+37  5.922886e+37 -6.845646e+37  1.585388e+37 -7.454759e+37 -1.310100e+37 -1.009898e+38\n",
      " -7.560860e+36 -2.018796e+36 -8.043519e+37  9.553839e+37  7.409157e+37  2.947659e+37 -3.847537e+37 -9.590151e+37\n",
      "  4.482262e+37  2.657899e+37  1.519527e+37  5.519570e+37]\n",
      "-2.045343284220147e+38 1.9666144794302594e+38\n",
      "---------------------\n",
      "Prediction: 1 == 1?\n",
      "[-3.260089917015278e+30, 7.599506198344162e+30, 4.904356006601706e+30, -8.460971521090669e+30, 4.090724259997935e+30]\n",
      "tensor([[0.3209, 0.2572, 0.2426, 0.2234, 0.2107]], grad_fn=<AddBackward0>)\n",
      "321.088018655777 seconds\n"
     ]
    }
   ],
   "source": [
    "for xx, yy in zip(X_valid[:4], y_valid[:4]):\n",
    "    t0 = time()\n",
    "    #print(len(xx))\n",
    "    ctx = featurizer.encrypt(xx)\n",
    "    result = nrf_evaluator(ctx)\n",
    "    #print(f\"Took {time() - t0:.2f} seconds\")\n",
    "\n",
    "    pred = []\n",
    "    for res in result:\n",
    "        dec = decrypt(secretKey, res)\n",
    "        pred.append(np.sum(dec))\n",
    "\n",
    "    print(f\"Prediction: {np.argmax(pred)} == {yy}?\") \n",
    "    neural_pred = Nmodel(torch.tensor(X_train[:1]).float())\n",
    "    print(pred)\n",
    "    print(neural_pred)\n",
    "    print(f\"{time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "104d1fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887150053714814"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b58f07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pred = Nmodel(torch.tensor(X_train[:1]).float())\n",
    "#Nmodel(torch.tensor(X_valid[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3891e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -68.3079,  -4021.2930, -13188.7412,  24814.9121, -10345.2754]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d66646",
   "metadata": {},
   "source": [
    "여기서 만든 h_rf와 새로 만든 h_rf의 모양, 값 차이 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0bd8e",
   "metadata": {},
   "source": [
    "min = 0, \n",
    "max = 1인데.. 왜 -1보다 작아질까...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "912b3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1354.7771911621098,\n",
       " -657.0239105224605,\n",
       " -13200.904769897461,\n",
       " 19254.122360229492,\n",
       " -9825.276138305662]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22183461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
