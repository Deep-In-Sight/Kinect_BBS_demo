{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b896c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecea81a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU version HEAAN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "#from fase.core import heaan\n",
    "\n",
    "from fase import HEAAN\n",
    "from fase import HEAAN as he\n",
    "from typing import List, Callable\n",
    "\n",
    "from fase import hnrf as hnrf\n",
    "\n",
    "from fase.hnrf.tree import NeuralTreeMaker\n",
    "from fase.hnrf import heaan_nrf \n",
    "from fase.hnrf.hetree import HomomorphicModel \n",
    "\n",
    "#import importlib\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19858082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_print(ctx, n=20):\n",
    "    res1 = decrypt(secretKey, ctx)\n",
    "    print(res1[:n])\n",
    "    \n",
    "def decrypt(secretKey, enc):\n",
    "    featurized = scheme.decrypt(secretKey, enc)\n",
    "    arr = np.zeros(n, dtype=np.complex128)\n",
    "    featurized.__getarr__(arr)\n",
    "    return arr.real\n",
    "\n",
    "def encrypt(val):\n",
    "    ctxt = he.Ciphertext()#logp, logq, n)\n",
    "    vv = np.zeros(n) # Need to initialize to zero or will cause \"unbound\"\n",
    "    vv[:len(val)] = val\n",
    "    scheme.encrypt(ctxt, he.Double(vv), n, logp, logq)\n",
    "    del vv\n",
    "    return ctxt\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "class TabularDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        'Initialization'\n",
    "        self.X, self.y = X,y\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        X = torch.tensor(self.X[index]).float()\n",
    "        y = torch.tensor(self.y[index])\n",
    "\n",
    "        return X, y\n",
    "\n",
    "class Param():\n",
    "    def __init__(self, n=None, logn=None, logp=None, logq=None, logQboot=None):\n",
    "        self.n = n\n",
    "        self.logn = logn\n",
    "        self.logp = logp\n",
    "        self.logq = logq \n",
    "        self.logQboot = logQboot\n",
    "        if self.logn == None:\n",
    "            self.logn = int(np.log2(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29953609",
   "metadata": {},
   "source": [
    "# Train a RF model  -- smaller example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401e18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "#print(fastai.__version__)\n",
    "\n",
    "from fastai.basic_data import DataBunch, DataLoader\n",
    "#from fastai.tabular.data import TabularDataLoaders\n",
    "\n",
    "from fastai.tabular.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "\n",
    "from fase.hnrf.tree import CrossEntropyLabelSmoothing\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c98f5",
   "metadata": {},
   "source": [
    "matcher를 풀고 train하면 성능이 쉽게 올라가지만 중간에 계산값이 +/- 1을 넘어갈 가능성이 높아질 것 같음.  \n",
    "근데 matcher 안 풀고는 좀처럼 성능이 올라가지 않음... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1404b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.3239795918367347\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.5103989089669281\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.34350850077279754\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.480054551653597\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.4448051948051948\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.4066461116820829\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.5973406068871463\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.4641114982578397\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.4283480979676915\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.48547505126452495\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.4429254955570745\n",
      "model's depth: 7\n",
      "model's tree count: 20\n",
      "Accuracy of tanh : 0.7621326042378674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import BaseDecisionTree\n",
    "from fase.hnrf.tree import NeuralRF\n",
    "\n",
    "model_dir = \"/home/hoseung/Work/Kinect_BBS_demo/nbs/\"\n",
    "\n",
    "CAM_LIST= {1: \"e\",\n",
    "           2: \"e\",\n",
    "           3: \"a\",\n",
    "           4: \"e\",\n",
    "           5: \"e\",\n",
    "           6: \"e\",\n",
    "           7: \"e\",\n",
    "           8: \"a\",\n",
    "           9: \"a\",\n",
    "           10:\"e\",\n",
    "           11:\"e\",\n",
    "           12:\"e\",\n",
    "           13:\"a\",\n",
    "           14:\"e\"}\n",
    "\n",
    "\n",
    "dilatation_factor = 15\n",
    "polynomial_degree = 21\n",
    "\n",
    "\n",
    "#for action in np.arange(1,15): \n",
    "# 3, 9는 아직 없음 , 12번 다시. \n",
    "for action in range(1,13):\n",
    "    cam = CAM_LIST[action]\n",
    "\n",
    "    fn_model_out = f\"trained_model_{action}_{cam}.pickle\"\n",
    "    fn_data_out = f\"BBS_dataset_{action}_{cam}.pickle\"\n",
    "\n",
    "    fn_model = model_dir + fn_model_out\n",
    "    fn_dat = model_dir + fn_data_out\n",
    "    \n",
    "    dataset = pickle.load(open(fn_dat, \"rb\"))\n",
    "\n",
    "    X_train = dataset[\"train_x\"]\n",
    "    y_train = dataset[\"train_y\"]\n",
    "    X_valid = dataset[\"valid_x\"]\n",
    "    y_valid = dataset[\"valid_y\"]\n",
    "\n",
    "    #print(\"min max of input dataset\")\n",
    "    #print(X_train.min(), X_train.max())\n",
    "    #print(X_valid.min(), X_valid.max())\n",
    "\n",
    "    rf_model = pickle.load(open(fn_model, \"rb\"))\n",
    "\n",
    "    print(\"model's depth:\", rf_model.max_depth)\n",
    "    print(\"model's tree count:\", rf_model.n_estimators)\n",
    "\n",
    "\n",
    "    estimators = rf_model.estimators_\n",
    "\n",
    "    my_tm_tanh = NeuralTreeMaker(torch.tanh, \n",
    "                                use_polynomial=True,\n",
    "                                dilatation_factor=dilatation_factor, \n",
    "                                polynomial_degree=polynomial_degree)\n",
    "\n",
    "    Nmodel =NeuralRF(estimators, my_tm_tanh)\n",
    "\n",
    "    # NRF 성능 테스트\n",
    "    with torch.no_grad():\n",
    "        neural_pred = Nmodel(torch.tensor(X_valid).float()).argmax(dim=1).numpy()\n",
    "\n",
    "    print(f\"Accuracy of tanh : {(neural_pred == y_valid).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b414ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7e3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d5532eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.9844497607655502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_890792/1254981868.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  print(f\"Accuracy of tanh : {(neural_pred == y_train).mean()}\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_890792/1254981868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original accuracy : {(pred == y_train).mean()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy of tanh : {(neural_pred == y_train).mean()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Match between tanh and original : {(neural_pred == pred).mean()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "pred = rf_model.predict(X_train)\n",
    "print(f\"Original accuracy : {(pred == y_train).mean()}\")\n",
    "print(f\"Accuracy of tanh : {(neural_pred == y_train).mean()}\")\n",
    "print(f\"Match between tanh and original : {(neural_pred == pred).mean()}\")\n",
    "\n",
    "\n",
    "####\n",
    "bs = 128\n",
    "\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "valid_ds = TabularDataset(X_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "fix_dl = DataLoader(train_ds, batch_size=bs, shuffle=False)\n",
    "\n",
    "Nmodel.freeze_layer(\"comparator\")\n",
    "Nmodel.freeze_layer(\"matcher\")\n",
    "\n",
    "for p in Nmodel.parameters():\n",
    "    print(p.shape, p.requires_grad)\n",
    "\n",
    "####\n",
    "data = DataBunch(train_dl, valid_dl, fix_dl=fix_dl)\n",
    "#data = TabularDataLoaders.from_dsets(train_dl, valid_dl, bs=64)\n",
    "\n",
    "criterion = CrossEntropyLabelSmoothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "067f0d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): operands do not broadcast with remapped shapes [original->remapped]: [5852, 241]->[5852, 1, 1, 241] [240, 92, 20]->[1, 92, 20, 240]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_890792/2017262241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mneural_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Original accuracy : {(pred == y_valid).mean()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newbbs/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/tree.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mcomparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;31m#print(\"1. comparisons\", comparisons)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparisons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/fhe-ai-sw-etri/fase/hnrf/tree.py\u001b[0m in \u001b[0;36mcompare\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# comparator.shape = (N_feature, N_branches, N_trees) => jil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# result be kil, or (N_example, N_branches, N_Trees)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mcomparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kj,jil->kil\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparator_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0mcomparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparisons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomparisons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/newbbs/lib/python3.9/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): operands do not broadcast with remapped shapes [original->remapped]: [5852, 241]->[5852, 1, 1, 241] [240, 92, 20]->[1, 92, 20, 240]"
     ]
    }
   ],
   "source": [
    "## Fine-tuned NRF model\n",
    "pred = rf_model.predict(X_valid)\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_pred = Nmodel(torch.tensor(X_valid).float()).argmax(dim=1).numpy()\n",
    "\n",
    "print(f\"Original accuracy : {(pred == y_valid).mean()}\")\n",
    "print(f\"Accuracy : {(neural_pred == y_valid).mean()}\")\n",
    "print(f\"Same output : {(neural_pred == pred).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "46c5b5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hoseung/Work/Kinect_BBS_demo/nbs'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0930588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fase.hnrf.hetree import HNRF\n",
    "action = 1\n",
    "cam = CAM_LIST[action]\n",
    "Nmodel = pickle.load(open(f\"Nmodel_{action}_{cam}.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c3bdd",
   "metadata": {},
   "source": [
    "이거를 빨리... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dd048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = heaan_nrf.HETreeFeaturizer(h_rf.return_comparator(), scheme, parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "104d1fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887150053714814"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b58f07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_pred = Nmodel(torch.tensor(X_train[:1]).float())\n",
    "#Nmodel(torch.tensor(X_valid[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3891e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   -68.3079,  -4021.2930, -13188.7412,  24814.9121, -10345.2754]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d66646",
   "metadata": {},
   "source": [
    "여기서 만든 h_rf와 새로 만든 h_rf의 모양, 값 차이 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea0bd8e",
   "metadata": {},
   "source": [
    "min = 0, \n",
    "max = 1인데.. 왜 -1보다 작아질까...? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "912b3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1354.7771911621098,\n",
       " -657.0239105224605,\n",
       " -13200.904769897461,\n",
       " 19254.122360229492,\n",
       " -9825.276138305662]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ccffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
